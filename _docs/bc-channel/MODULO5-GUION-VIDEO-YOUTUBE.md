# GUI√ìN PARA VIDEO DE YOUTUBE - M√ìDULO 5

## BOOTCAMP BASH SCRIPTING: MANIPULACI√ìN AVANZADA DE DATOS

---

### üìã INFORMACI√ìN DEL VIDEO

**T√≠tulo:** "Bash Scripting Avanzado: Manipulaci√≥n de Datos, Arrays y Expresiones Regulares | M√≥dulo 5"

**Duraci√≥n estimada:** 90-120 minutos

**Audiencia:** Programadores intermedios que han completado los m√≥dulos 1-4

**Objetivos del m√≥dulo:**

- Dominar arrays indexados y asociativos en Bash
- Comprender y aplicar expresiones regulares avanzadas
- Utilizar sed y awk para procesamiento complejo de texto
- Desarrollar un analizador de logs profesional

---

## üé¨ ESTRUCTURA DEL VIDEO

### PARTE 1: INTRODUCCI√ìN Y ARRAYS (0:00 - 25:00)

- Bienvenida e introducci√≥n al m√≥dulo
- Arrays indexados: declaraci√≥n, acceso y manipulaci√≥n
- Arrays asociativos: conceptos y casos de uso
- Operaciones avanzadas con arrays

### PARTE 2: EXPRESIONES REGULARES (25:00 - 50:00)

- Fundamentos de expresiones regulares
- Cuantificadores y clases de caracteres
- Grupos y capturas
- Integraci√≥n con herramientas de Bash

### PARTE 3: SED Y AWK AVANZADOS (50:00 - 75:00)

- sed: hold space y comandos m√∫ltiples
- awk: variables, funciones y l√≥gica compleja
- Casos de uso pr√°cticos y pipelines

### PARTE 4: PROYECTO PR√ÅCTICO (75:00 - 120:00)

- Dise√±o del analizador de logs
- Implementaci√≥n modular
- Testing y demostraci√≥n
- Conclusiones y siguientes pasos

---

## üéØ PARTE 1: INTRODUCCI√ìN Y ARRAYS

### Tiempo: 0:00 - 25:00

#### [0:00 - 2:00] BIENVENIDA E INTRODUCCI√ìN

**[PANTALLA: Logo del Bootcamp + T√≠tulo del M√≥dulo]**

¬°Hola y bienvenidos de nuevo al Bootcamp de Bash Scripting! Soy tu instructor y hoy vamos a abordar uno de los m√≥dulos m√°s emocionantes y transformadores de todo nuestro programa: el **M√≥dulo 5 - Manipulaci√≥n Avanzada de Datos**.

**[PANTALLA: Transici√≥n con gr√°fico mostrando la progresi√≥n del bootcamp]**

Si has seguido el bootcamp desde el principio, ya tienes una base s√≥lida. En el M√≥dulo 1 aprendiste los fundamentos, en el 2 dominaste comandos avanzados y pipes, en el 3 controlaste variables y flujo, y en el 4 conquistaste funciones y arrays b√°sicos.

**[PANTALLA: Diagrama mostrando c√≥mo se conectan los m√≥dulos]**

Hoy, en el M√≥dulo 5, vamos a hacer un salto cualitativo. Vamos a transformarte de un programador de bash competente a alguien que puede manejar datos complejos como un verdadero experto. Al final de este m√≥dulo, podr√°s crear herramientas que rivalizan con scripts de Python para ciertas tareas.

**[PANTALLA: Preview del proyecto final - screenshots del analizador de logs]**

Y para demostrarlo, vamos a construir juntos un analizador de logs profesional que puede procesar logs de Apache, Nginx, aplicaciones personalizadas, detectar anomal√≠as de seguridad, generar reportes ejecutivos, y crear dashboards HTML interactivos. ¬°Es el tipo de herramienta que podr√≠as usar ma√±ana mismo en tu trabajo!

#### [2:00 - 3:30] ESTRUCTURA DEL M√ìDULO

**[PANTALLA: √çndice visual del m√≥dulo con iconos]**

Nuestro viaje de hoy est√° estructurado en tres lecciones principales m√°s un proyecto pr√°ctico:

1. **Lecci√≥n 5.1: Arrays y Estructuras de Datos** - Aprenderemos a organizar informaci√≥n compleja de manera eficiente
2. **Lecci√≥n 5.2: Expresiones Regulares** - Dominaremos el "superpoder" para encontrar patrones en texto
3. **Lecci√≥n 5.3: Procesamiento Avanzado con sed y awk** - Integraremos herramientas poderosas para transformaciones complejas
4. **Proyecto Pr√°ctico 5: Analizador de Logs** - Aplicaremos todo en una herramienta profesional

**[PANTALLA: Diagrama de flujo mostrando c√≥mo cada lecci√≥n contribuye al proyecto]**

Cada lecci√≥n construye sobre la anterior, creando una progresi√≥n natural hacia la maestr√≠a. Los arrays nos dan la estructura, las expresiones regulares nos dan la precisi√≥n, sed y awk nos dan la potencia, y el proyecto final nos da la experiencia pr√°ctica.

#### [3:30 - 5:00] ¬øPOR QU√â ESTE M√ìDULO ES CRUCIAL?

**[PANTALLA: Gr√°fico mostrando estad√≠sticas sobre volumen de datos en empresas]**

En el mundo actual, manejamos cantidades masivas de datos textuales: logs de servidores, archivos CSV, APIs JSON, configuraciones XML, reportes de sistemas. La capacidad de procesar, analizar y extraer insights de estos datos no es solo una habilidad t√©cnica nice-to-have, es una **competencia esencial** para cualquier profesional t√©cnico.

**[PANTALLA: Ejemplos visuales de tipos de datos que procesaremos]**

Las t√©cnicas que aprender√°s hoy te permitir√°n:

- Analizar logs de millones de l√≠neas en segundos
- Extraer patrones complejos de datasets grandes
- Crear reportes autom√°ticos que ahorren horas de trabajo manual
- Detectar problemas de seguridad y rendimiento proactivamente

**[PANTALLA: Testimonial imaginario o case study]**

Y lo mejor de todo: estas son habilidades nativas de Unix/Linux. No necesitas instalar Python, Java, o frameworks complejos. Todo lo que aprender√°s funciona en cualquier sistema Unix/Linux out-of-the-box.

#### [5:00 - 8:00] LECCI√ìN 5.1: INTRODUCCI√ìN A ARRAYS

**[PANTALLA: Transici√≥n a Lecci√≥n 5.1 con animaci√≥n]**

¬°Empezamos con la Lecci√≥n 5.1: Arrays y Estructuras de Datos!

**[PANTALLA: Analog√≠a visual - caja de herramientas con compartimentos numerados]**

Imagina que tienes una caja de herramientas donde cada compartimento tiene un n√∫mero y dentro guardas diferentes herramientas. Esto es exactamente lo que hace un array: es un contenedor que nos permite almacenar m√∫ltiples valores bajo un mismo nombre, organizados por posici√≥n o por clave.

**[PANTALLA: C√≥digo en pantalla - terminal preparado]**

En Bash tenemos dos tipos principales de arrays:

1. **Arrays indexados**: Usan n√∫meros como √≠ndices (0, 1, 2, etc.)
2. **Arrays asociativos**: Usan cadenas como √≠ndices (como "nombre", "edad", etc.)

Empezemos con los arrays indexados, que son los m√°s comunes y f√°ciles de entender.

#### [8:00 - 12:00] ARRAYS INDEXADOS: DECLARACI√ìN Y ASIGNACI√ìN

**[PANTALLA: Terminal en vivo - creando archivo de ejemplo]**

```bash
# Vamos a crear nuestro primer script de ejemplo
nano arrays_basicos.sh
```

**[PANTALLA: Escribiendo c√≥digo en vivo en el editor]**

```bash
#!/bin/bash
# arrays_basicos.sh - Ejemplos de arrays indexados
set -euo pipefail

echo "=== DECLARACI√ìN DE ARRAYS ==="

# M√©todo 1: Declaraci√≥n expl√≠cita
declare -a servidores
servidores[0]="web01"
servidores[1]="web02"
servidores[2]="db01"

echo "Servidores declarados individualmente:"
echo "${servidores[@]}"

# M√©todo 2: Asignaci√≥n directa
nombres=("Juan" "Mar√≠a" "Carlos" "Ana")
echo "Nombres asignados directamente: ${nombres[@]}"

# M√©todo 3: Desde la salida de un comando
archivos=($(ls *.sh))
echo "Scripts en el directorio actual: ${archivos[@]}"

# M√©todo 4: Lectura desde archivo
# Primero creamos un archivo de ejemplo
echo -e "192.168.1.1\n192.168.1.2\n192.168.1.3" > ips.txt
readarray -t direcciones_ip < ips.txt
echo "IPs le√≠das desde archivo: ${direcciones_ip[@]}"
```

**[PANTALLA: Ejecutando el script paso a paso]**

```bash
chmod +x arrays_basicos.sh
./arrays_basicos.sh
```

**[EXPLICACI√ìN MIENTRAS SE EJECUTA]**

F√≠jate en varios puntos importantes aqu√≠:

1. **`declare -a`** es la forma expl√≠cita de declarar un array, aunque no siempre es necesaria
2. **Los √≠ndices empiezan en 0**, como en la mayor√≠a de lenguajes de programaci√≥n
3. **`${array[@]}`** expande todos los elementos del array
4. **`readarray -t`** es la forma m√°s robusta de leer l√≠neas desde un archivo

#### [12:00 - 16:00] ACCESO Y MODIFICACI√ìN DE ARRAYS

**[PANTALLA: Creando nuevo script m√°s avanzado]**

```bash
nano arrays_avanzados.sh
```

```bash
#!/bin/bash
# arrays_avanzados.sh - Operaciones avanzadas con arrays
set -euo pipefail

# Inicializamos un array de ejemplo
servicios=("apache" "nginx" "mysql" "postgresql" "redis")

echo "=== ACCESO A ELEMENTOS ==="
echo "Primer servicio: ${servicios[0]}"
echo "√öltimo servicio: ${servicios[-1]}"  # Bash 4.3+
echo "Tercer servicio: ${servicios[2]}"

echo -e "\n=== INFORMACI√ìN DEL ARRAY ==="
echo "Todos los elementos: ${servicios[@]}"
echo "N√∫mero de elementos: ${#servicios[@]}"
echo "√çndices disponibles: ${!servicios[@]}"

echo -e "\n=== MODIFICACI√ìN DE ELEMENTOS ==="
servicios[1]="nginx-updated"
echo "Despu√©s de modificar √≠ndice 1: ${servicios[@]}"

# Agregar elementos
servicios+=("mongodb")
servicios+=("elasticsearch")
echo "Despu√©s de agregar elementos: ${servicios[@]}"

echo -e "\n=== SLICING DE ARRAYS ==="
echo "Primeros 3 elementos: ${servicios[@]:0:3}"
echo "Desde el √≠ndice 2: ${servicios[@]:2}"
echo "√öltimos 2 elementos: ${servicios[@]: -2}"

echo -e "\n=== B√öSQUEDA EN ARRAYS ==="
buscar="mysql"
for i in "${!servicios[@]}"; do
    if [[ "${servicios[$i]}" == "$buscar" ]]; then
        echo "Encontrado '$buscar' en √≠ndice $i"
        break
    fi
done
```

**[PANTALLA: Ejecutando y explicando cada secci√≥n]**

```bash
chmod +x arrays_avanzados.sh
./arrays_avanzados.sh
```

**[EXPLICACI√ìN EN VIVO]**

Lo que acabas de ver son t√©cnicas que separan a un programador principiante de uno intermedio:

- **`${array[-1]}`** para acceder al √∫ltimo elemento (requiere Bash 4.3+)
- **`${#array[@]}`** para obtener la longitud
- **`${!array[@]}`** para obtener los √≠ndices (s√∫per √∫til para arrays con gaps)
- **Slicing con `${array[@]:start:length}`** como en Python
- **Array expansion con `+=`** para agregar elementos eficientemente

#### [16:00 - 20:00] ITERACI√ìN SOBRE ARRAYS

**[PANTALLA: Nuevo script enfocado en iteraci√≥n]**

```bash
nano arrays_iteracion.sh
```

```bash
#!/bin/bash
# arrays_iteracion.sh - T√©cnicas de iteraci√≥n
set -euo pipefail

# Array de ejemplo con datos de log
log_files=("/var/log/apache2/access.log" "/var/log/nginx/access.log"
           "/var/log/mysql/error.log" "/var/log/syslog")

echo "=== ITERACI√ìN M√âTODO 1: Sobre elementos ==="
for archivo in "${log_files[@]}"; do
    echo "Procesando: $archivo"
    # Simulamos procesamiento
    echo "  - Tama√±o: $(wc -c <<< "$archivo") bytes (simulado)"
done

echo -e "\n=== ITERACI√ìN M√âTODO 2: Por √≠ndices ==="
for i in "${!log_files[@]}"; do
    echo "Archivo #$i: ${log_files[$i]}"
    # √ötil cuando necesitas tanto el √≠ndice como el valor
done

echo -e "\n=== ITERACI√ìN M√âTODO 3: Estilo C ==="
for ((i=0; i<${#log_files[@]}; i++)); do
    echo "Posici√≥n $i contiene: ${log_files[$i]}"
done

echo -e "\n=== ITERACI√ìN CONDICIONAL ==="
for archivo in "${log_files[@]}"; do
    if [[ "$archivo" == *"error"* ]]; then
        echo "üö® ARCHIVO DE ERROR ENCONTRADO: $archivo"
    elif [[ "$archivo" == *"access"* ]]; then
        echo "üìä Archivo de acceso: $archivo"
    else
        echo "üìù Otro tipo de log: $archivo"
    fi
done

echo -e "\n=== PROCESAMIENTO CON WHILE ==="
i=0
while [[ $i -lt ${#log_files[@]} ]]; do
    archivo="${log_files[$i]}"
    echo "Procesando archivo $((i+1))/${#log_files[@]}: $(basename "$archivo")"
    ((i++))
done
```

**[PANTALLA: Ejecutando con explicaciones detalladas]**

```bash
chmod +x arrays_iteracion.sh
./arrays_iteracion.sh
```

**[EXPLICACI√ìN MIENTRAS SE EJECUTA]**

F√≠jate en las diferentes t√©cnicas de iteraci√≥n:

1. **Iteraci√≥n directa sobre elementos**: M√°s simple y legible
2. **Iteraci√≥n por √≠ndices**: √ötil cuando necesitas la posici√≥n
3. **Estilo C**: Familiar para programadores de otros lenguajes
4. **Iteraci√≥n condicional**: Combina loops con l√≥gica de negocio
5. **While loops**: M√°s control sobre la iteraci√≥n

#### [20:00 - 25:00] ARRAYS ASOCIATIVOS

**[PANTALLA: Transici√≥n a arrays asociativos con animaci√≥n]**

Ahora vamos a dar un salto conceptual importante. Los arrays asociativos son como un paso evolutivo de los arrays indexados. En lugar de usar n√∫meros como √≠ndices, puedes usar palabras o frases que tengan significado.

**[PANTALLA: Analog√≠a visual - agenda telef√≥nica vs lista numerada]**

Piensa en un array asociativo como una agenda telef√≥nica: en lugar de buscar por posici√≥n num√©rica, buscas por nombre de persona. Esto hace que tu c√≥digo sea mucho m√°s legible y mantenible.

**[PANTALLA: Nuevo script para arrays asociativos]**

```bash
nano arrays_asociativos.sh
```

```bash
#!/bin/bash
# arrays_asociativos.sh - Trabajando con arrays asociativos
set -euo pipefail

# Declaraci√≥n obligatoria para arrays asociativos
declare -A servidor_info
declare -A metricas_sistema
declare -A usuarios_activos

echo "=== DECLARACI√ìN Y ASIGNACI√ìN ==="

# M√©todo 1: Asignaci√≥n individual
servidor_info["nombre"]="web01"
servidor_info["ip"]="192.168.1.10"
servidor_info["os"]="Ubuntu 22.04"
servidor_info["ram"]="16GB"
servidor_info["cpu"]="Intel Xeon"

echo "Informaci√≥n del servidor:"
for clave in "${!servidor_info[@]}"; do
    echo "  $clave: ${servidor_info[$clave]}"
done

# M√©todo 2: Asignaci√≥n m√∫ltiple
metricas_sistema=(
    ["cpu_usage"]="15%"
    ["memory_usage"]="8.2GB"
    ["disk_usage"]="45%"
    ["network_rx"]="1.2MB/s"
    ["network_tx"]="800KB/s"
    ["uptime"]="15 days"
)

echo -e "\nM√©tricas del sistema:"
for metrica in "${!metricas_sistema[@]}"; do
    echo "  $metrica: ${metricas_sistema[$metrica]}"
done

echo -e "\n=== OPERACIONES AVANZADAS ==="

# Verificar si existe una clave
if [[ -v servidor_info["ip"] ]]; then
    echo "‚úÖ La IP del servidor est√° configurada: ${servidor_info["ip"]}"
fi

# Agregar nuevas entradas din√°micamente
servidor_info["puerto_ssh"]="22"
servidor_info["estado"]="activo"

echo -e "\nServidor despu√©s de agregar campos:"
for campo in nombre ip estado puerto_ssh; do
    if [[ -v servidor_info["$campo"] ]]; then
        echo "  $campo: ${servidor_info[$campo]}"
    fi
done

# Eliminar entradas
unset servidor_info["puerto_ssh"]
echo -e "\nDespu√©s de eliminar puerto_ssh:"
echo "Claves restantes: ${!servidor_info[@]}"
```

**[PANTALLA: Ejecutando y explicando conceptos clave]**

```bash
chmod +x arrays_asociativos.sh
./arrays_asociativos.sh
```

**[EXPLICACI√ìN FUNDAMENTAL]**

Los arrays asociativos requieren algunas consideraciones especiales:

1. **`declare -A` es obligatorio** - Sin esto, Bash los trata como arrays normales
2. **Las claves pueden ser cualquier string** - Incluso con espacios si usas comillas
3. **`-v` para verificar existencia** - `[[ -v array["key"] ]]` es la forma correcta
4. **`unset` para eliminar** - Elimina tanto la clave como el valor

---

## üéØ PARTE 2: EXPRESIONES REGULARES

### Tiempo: 25:00 - 50:00

#### [25:00 - 27:00] BIENVENIDA A LA PARTE 2 E INTRODUCCI√ìN

**[PANTALLA: Transici√≥n animada con t√≠tulo "Parte 2: Expresiones Regulares"]**

¬°Bienvenidos de vuelta! Espero que hayas disfrutado experimentando con arrays durante el descanso. Ahora vamos a adentrarnos en uno de los temas m√°s poderosos y transformadores del bash scripting: **las Expresiones Regulares**.

**[PANTALLA: Analog√≠a visual - detective con lupa examinando documentos]**

Imagina que eres detective y necesitas encontrar pistas espec√≠ficas en miles de documentos. Las expresiones regulares son como tener una lupa m√°gica que puede encontrar exactamente lo que buscas, sin importar cu√°n complejo sea el patr√≥n.

**[PANTALLA: Comparaci√≥n visual entre b√∫squeda literal vs b√∫squeda por patrones]**

No buscan solo texto literal como "buscar juan en el documento", sino que pueden buscar **patrones** como:

- "Cualquier palabra que empiece con J, tenga entre 4 y 8 letras, y termine en vocal"
- "Todos los emails en este archivo"
- "Fechas en formato dd/mm/yyyy"
- "N√∫meros de tel√©fono en cualquier formato com√∫n"

**[PANTALLA: Estad√≠stica visual sobre el impacto de dominar regex]**

Las expresiones regulares son una de esas habilidades que, una vez que las dominas, cambian completamente tu forma de trabajar con texto y datos. Son utilizadas en pr√°cticamente todos los lenguajes de programaci√≥n y herramientas de procesamiento de texto.

#### [27:00 - 32:00] FUNDAMENTOS Y PATRONES B√ÅSICOS

**[PANTALLA: Terminal preparado + editor de texto]**

Empezemos con los elementos m√°s b√°sicos. Cada s√≠mbolo en una expresi√≥n regular tiene un significado espec√≠fico, como aprender el alfabeto antes de formar palabras.

**[PANTALLA: Creando archivo de pr√°ctica]**

```bash
# Primero creamos datos de ejemplo para practicar
nano datos_ejemplo.txt
```

**[PANTALLA: Escribiendo datos de ejemplo en vivo]**

```text
Juan P√©rez - email: juan.perez@empresa.com - Tel: 555-1234
Mar√≠a Garc√≠a - email: maria.garcia@universidad.edu - Tel: (555) 987-6543
Carlos L√≥pez - email: c.lopez@startup.io - Tel: 555.789.0123
Ana Rodr√≠guez - email: ana.rodriguez@consultoria.org - Tel: +1-555-456-7890

Logs del servidor:
[2024-03-15 09:15:30] INFO: Usuario 'admin' inici√≥ sesi√≥n desde 192.168.1.100
[2024-03-15 09:16:45] WARNING: Intento de acceso fallido desde 10.0.0.50
[2024-03-15 09:17:12] ERROR: Base de datos no responde en puerto 3306
[2024-03-15 10:25:18] INFO: Backup completado - 2.5GB transferidos

Productos y precios:
- Laptop HP ProBook: $899.99
- Mouse inal√°mbrico: $29.95
- Monitor 24": $199.00
- Teclado mec√°nico: $79.99
```

**[PANTALLA: Guardando y empezando con ejemplos b√°sicos]**

Ahora vamos a crear nuestro primer script de expresiones regulares:

```bash
nano regex_basicos.sh
```

```bash
#!/bin/bash
# regex_basicos.sh - Fundamentos de expresiones regulares
set -euo pipefail

ARCHIVO="datos_ejemplo.txt"

echo "=== PATRONES LITERALES ==="
echo "Buscando la palabra 'email':"
grep "email" "$ARCHIVO"

echo -e "\n=== METACARACTERES B√ÅSICOS ==="
echo "El punto (.) coincide con cualquier car√°cter:"
grep "..@" "$ARCHIVO"  # Cualquier cosa seguida de @

echo -e "\nEl asterisco (*) significa 'cero o m√°s del car√°cter anterior':"
grep "55*" "$ARCHIVO"  # 5 seguido de cero o m√°s 5s

echo -e "\n=== ANCLAS ==="
echo "L√≠neas que empiezan con '[' (inicio de l√≠nea):"
grep "^\\[" "$ARCHIVO"

echo -e "\nL√≠neas que terminan con un n√∫mero (final de l√≠nea):"
grep "[0-9]$" "$ARCHIVO"

echo -e "\n=== CLASES DE CARACTERES ==="
echo "Cualquier d√≠gito [0-9]:"
grep "[0-9]" "$ARCHIVO"

echo -e "\nVocales [aeiou]:"
grep "[aeiou]" "$ARCHIVO"

echo -e "\nNo d√≠gitos [^0-9] (negaci√≥n):"
grep "[^0-9]" "$ARCHIVO" | head -3  # Solo primeras 3 l√≠neas
```

**[PANTALLA: Ejecutando y explicando cada patr√≥n]**

```bash
chmod +x regex_basicos.sh
./regex_basicos.sh
```

**[EXPLICACI√ìN MIENTRAS SE EJECUTA]**

F√≠jate en los conceptos fundamentales:

1. **Caracteres literales**: Buscan exactamente lo que escribes
2. **Metacaracteres**: Tienen significados especiales (. \* ^ $ [ ] \ | ( ) + ? { })
3. **Anclas**: `^` para inicio de l√≠nea, `$` para final
4. **Clases de caracteres**: `[abc]` coincide con a, b, o c
5. **Negaci√≥n**: `[^abc]` coincide con cualquier cosa EXCEPTO a, b, o c

#### [32:00 - 37:00] CUANTIFICADORES - EL PODER DE LA REPETICI√ìN

**[PANTALLA: Nuevo script enfocado en cuantificadores]**

Los cuantificadores son como especificar "cu√°ntas veces" quieres que algo aparezca. Es la diferencia entre buscar "una letra" versus "entre 3 y 5 letras".

```bash
nano regex_cuantificadores.sh
```

```bash
#!/bin/bash
# regex_cuantificadores.sh - Cuantificadores y repetici√≥n
set -euo pipefail

ARCHIVO="datos_ejemplo.txt"

echo "=== CUANTIFICADORES B√ÅSICOS ==="

echo "* = cero o m√°s repeticiones:"
echo "N√∫meros seguidos de ceros o m√°s d√≠gitos:"
grep -E "[0-9][0-9]*" "$ARCHIVO"

echo -e "\n+ = una o m√°s repeticiones:"
echo "Al menos un d√≠gito seguido de m√°s d√≠gitos:"
grep -E "[0-9]+" "$ARCHIVO"

echo -e "\n? = cero o una repetici√≥n (opcional):"
echo "Color con 'u' opcional (color/colour):"
echo -e "color\ncolour\ncolooour" | grep -E "colou?r"

echo -e "\n=== CUANTIFICADORES ESPEC√çFICOS ==="

echo "{n} = exactamente n repeticiones:"
echo "Exactamente 3 d√≠gitos seguidos:"
grep -E "[0-9]{3}" "$ARCHIVO"

echo -e "\n{n,} = n o m√°s repeticiones:"
echo "4 o m√°s d√≠gitos seguidos:"
grep -E "[0-9]{4,}" "$ARCHIVO"

echo -e "\n{n,m} = entre n y m repeticiones:"
echo "Entre 2 y 4 letras seguidas:"
grep -E "[a-zA-Z]{2,4}" "$ARCHIVO"

echo -e "\n=== EJEMPLOS PR√ÅCTICOS ==="

echo "Validando formatos de tel√©fono:"
echo "Patr√≥n: 3 d√≠gitos, gui√≥n, 4 d√≠gitos"
grep -E "[0-9]{3}-[0-9]{4}" "$ARCHIVO"

echo -e "\nBuscando precios ($ seguido de d√≠gitos y punto decimal):"
grep -E "\\$[0-9]+\\.[0-9]{2}" "$ARCHIVO"

echo -e "\nFechas en formato YYYY-MM-DD:"
grep -E "[0-9]{4}-[0-9]{2}-[0-9]{2}" "$ARCHIVO"
```

**[PANTALLA: Ejecutando con explicaciones detalladas]**

```bash
chmod +x regex_cuantificadores.sh
./regex_cuantificadores.sh
```

**[EXPLICACI√ìN EN VIVO]**

Los cuantificadores transforman las expresiones regulares de herramientas b√°sicas a instrumentos precisos:

- **`*`**: "Cero o m√°s" - muy permisivo
- **`+`**: "Uno o m√°s" - requiere al menos una ocurrencia
- **`?`**: "Opcional" - puede estar o no estar
- **`{n}`**: "Exactamente n" - precisi√≥n exacta
- **`{n,m}`**: "Entre n y m" - rangos flexibles

#### [37:00 - 42:00] CLASES DE CARACTERES AVANZADAS

**[PANTALLA: Transici√≥n a clases POSIX y caracteres especiales]**

Las clases de caracteres b√°sicas como `[0-9]` son √∫tiles, pero existe un mundo mucho m√°s rico. Las clases POSIX nos dan precisi√≥n profesional para trabajar con texto internacional.

```bash
nano regex_clases_avanzadas.sh
```

```bash
#!/bin/bash
# regex_clases_avanzadas.sh - Clases de caracteres profesionales
set -euo pipefail

# Creamos datos con caracteres internacionales
cat << 'EOF' > datos_internacionales.txt
Nombres: Jos√©, Fran√ßois, M√ºller, √òystein, ≈Åukasz
Emails: jose@example.com, fran√ßois@universit√©.fr, m√ºller@firma.de
URLs: https://www.google.com, http://espa√±a.es, ftp://files.org
C√≥digos: ABC123, XYZ789, #hashtag, @usuario, 50% descuento
Fechas: 2024-03-15, 15/03/2024, Mar 15 2024
EOF

ARCHIVO="datos_internacionales.txt"

echo "=== CLASES POSIX B√ÅSICAS ==="

echo "[:alpha:] = letras (incluyendo acentos):"
grep -E "[[:alpha:]]+" "$ARCHIVO"

echo -e "\n[:digit:] = d√≠gitos:"
grep -E "[[:digit:]]+" "$ARCHIVO"

echo -e "\n[:alnum:] = alfanum√©rico:"
grep -E "[[:alnum:]]+" "$ARCHIVO"

echo -e "\n[:space:] = espacios en blanco:"
grep -E "[[:space:]]" "$ARCHIVO" | head -2

echo -e "\n=== CLASES POSIX AVANZADAS ==="

echo "[:upper:] = may√∫sculas:"
grep -E "[[:upper:]]{2,}" "$ARCHIVO"

echo -e "\n[:lower:] = min√∫sculas:"
grep -E "[[:lower:]]{3,}" "$ARCHIVO"

echo -e "\n[:punct:] = puntuaci√≥n:"
grep -E "[[:punct:]]" "$ARCHIVO"

echo -e "\n=== COMBINACIONES PROFESIONALES ==="

echo "Emails v√°lidos (patr√≥n b√°sico):"
grep -E "[[:alnum:]._-]+@[[:alnum:].-]+\\.[[:alpha:]]{2,}" "$ARCHIVO"

echo -e "\nURLs (http/https/ftp):"
grep -E "(https?|ftp)://[[:alnum:].-]+\\.[[:alpha:]]{2,}" "$ARCHIVO"

echo -e "\nC√≥digos alfanum√©ricos (letras + n√∫meros):"
grep -E "[[:upper:]]+[[:digit:]]+" "$ARCHIVO"

echo -e "\n=== ESCAPES Y CARACTERES ESPECIALES ==="

echo "S√≠mbolos especiales escapados:"
grep -E "\\$|%|#|@" "$ARCHIVO"

echo -e "\nPar√©ntesis literales (escapados):"
echo "(ejemplo)" | grep -E "\\([[:alpha:]]+\\)"

echo -e "\nPuntos literales en nombres de archivo:"
echo "archivo.txt" | grep -E "[[:alnum:]]+\\.[[:alpha:]]{3}"
```

**[PANTALLA: Ejecutando con explicaciones sobre internacionalizaci√≥n]**

```bash
chmod +x regex_clases_avanzadas.sh
./regex_clases_avanzadas.sh
```

**[EXPLICACI√ìN CR√çTICA]**

Las clases POSIX son cruciales para c√≥digo profesional porque:

1. **`[[:alpha:]]` incluye acentos** - `[a-z]` no reconoce √±, √©, √º
2. **Son independientes del locale** - Funcionan consistentemente
3. **M√°s legibles** - `[[:digit:]]` es m√°s claro que `[0-9]`
4. **Compatibilidad internacional** - Esencial para aplicaciones globales

#### [42:00 - 47:00] GRUPOS Y CAPTURAS

**[PANTALLA: Transici√≥n a la caracter√≠stica m√°s poderosa]**

Los grupos y capturas son la caracter√≠stica m√°s poderosa de las expresiones regulares. No solo te permiten buscar patrones, sino tambi√©n extraer y manipular partes espec√≠ficas.

```bash
nano regex_grupos_capturas.sh
```

```bash
#!/bin/bash
# regex_grupos_capturas.sh - Grupos y capturas avanzadas
set -euo pipefail

# Datos de ejemplo m√°s complejos
cat << 'EOF' > logs_servidor.txt
2024-03-15 09:15:30 [SECURITY] LOGIN_SUCCESS user=admin ip=192.168.1.100 session=abc123
2024-03-15 09:16:45 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:17:12 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:18:01 [SECURITY] LOGIN_FAILED user=admin ip=10.0.0.50 reason=invalid_password
2024-03-15 09:19:33 [SECURITY] FILE_ACCESS user=admin file=/etc/passwd action=read
2024-03-15 09:20:15 [SECURITY] LOGIN_SUCCESS user=operator ip=192.168.1.101 session=def456
2024-03-15 09:21:22 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:22:45 [SECURITY] PERMISSION_DENIED user=operator file=/root/secret.txt
2024-03-15 09:23:12 [SECURITY] LOGOUT user=admin session=abc123
EOF

ARCHIVO="logs_servidor.txt"

echo "=== GRUPOS B√ÅSICOS ==="

echo "Agrupando con par√©ntesis ():"
echo "Fechas y horas juntas:"
grep -E "(2024-[0-9]{2}-[0-9]{2}) ([0-9]{2}:[0-9]{2}:[0-9]{2})" "$ARCHIVO"

echo -e "\nAlternativas con | (OR):"
echo "M√©todos HTTP espec√≠ficos:"
grep -E "(GET|POST|DELETE)" "$ARCHIVO"

echo -e "\n=== CAPTURAS CON SED ==="

echo "Extrayendo solo las fechas:"
sed -E 's/^([0-9]{4}-[0-9]{2}-[0-9]{2}).*/\\1/' "$ARCHIVO"

echo -e "\nExtrayendo m√©todo y URL:"
sed -E 's/.*\\[.*\\] ([A-Z]+) ([^ ]+).*/M√©todo: \\1, URL: \\2/' "$ARCHIVO"

echo -e "\nTransformando formato de hora:"
sed -E 's/([0-9]{4}-[0-9]{2}-[0-9]{2}) ([0-9]{2}:[0-9]{2}):[0-9]{2}/\\1 \\2/' "$ARCHIVO"

echo -e "\n=== CAPTURAS CON AWK ==="

echo "Analizando tiempos de respuesta:"
awk '{
    if (match($0, /([0-9]+\.[0-9]+)s/, tiempo)) {
        if (tiempo[1] > 1.0) {
            print "‚ö†Ô∏è  LENTO:", $0
        } else if (tiempo[1] > 0.5) {
            print "‚ö° MEDIO:", $0
        } else {
            print "‚úÖ R√ÅPIDO:", $0
        }
    }
}' "$ARCHIVO"

echo -e "\n=== VALIDACI√ìN AVANZADA ==="

# Creamos datos para validar
cat << 'EOF' > datos_validacion.txt
juan.perez@empresa.com
maria.garcia@universidad.edu
invalido@
@dominio.com
correo.valido@sub.dominio.org
usuario_123@test-site.co.uk
EOF

echo "Emails v√°lidos (patr√≥n robusto):"
grep -E "^[[:alnum:]._-]+@[[:alnum:]-]+\\.[[:alpha:]]{2,}(\\.[[:alpha:]]{2,})?$" datos_validacion.txt

echo -e "\n=== REEMPLAZO INTELIGENTE ==="

echo "Anonimizando IPs en logs (manteniendo estructura):"
echo "192.168.1.100 - Usuario accedi√≥" | sed -E 's/([0-9]{1,3}\\.){3}[0-9]{1,3}/XXX.XXX.XXX.XXX/'

echo -e "\nFormateando n√∫meros de tel√©fono:"
echo "5551234567" | sed -E 's/([0-9]{3})([0-9]{3})([0-9]{4})/(\\1) \\2-\\3/'

echo -e "\nExtrayendo dominios de emails:"
sed -E 's/.*@([[:alnum:]-]+\\.[[:alpha:]]{2,}).*/\\1/' datos_validacion.txt | grep -v "@"
```

**[PANTALLA: Ejecutando paso a paso con explicaciones detalladas]**

```bash
chmod +x regex_grupos_capturas.sh
./regex_grupos_capturas.sh
```

**[EXPLICACI√ìN AVANZADA]**

Los grupos y capturas nos permiten:

1. **`()` para agrupar** - Tratar m√∫ltiples caracteres como unidad
2. **`|` para alternativas** - "esto O aquello"
3. **`\\1, \\2, \\3`** - Referencias a grupos capturados
4. **Validaci√≥n robusta** - Patrones que rechazan datos inv√°lidos
5. **Transformaci√≥n inteligente** - Reorganizar datos manteniendo estructura

#### [47:00 - 50:00] INTEGRACI√ìN CON HERRAMIENTAS DE BASH

**[PANTALLA: Mostrando el poder combinado]**

Ahora que dominas las expresiones regulares, veamos c√≥mo se integran perfectamente con las herramientas m√°s poderosas de Bash. Esta integraci√≥n es donde la magia realmente sucede.

```bash
nano regex_herramientas_bash.sh
```

```bash
#!/bin/bash
# regex_herramientas_bash.sh - Integraci√≥n con herramientas de Bash
set -euo pipefail

# Creamos un log m√°s realista
cat << 'EOF' > access_log.txt
192.168.1.101 - - [15/Mar/2024:09:15:30 +0000] "GET /index.html HTTP/1.1" 200 2326
10.0.0.50 - - [15/Mar/2024:09:16:45 +0000] "POST /login HTTP/1.1" 401 1024
192.168.1.102 - - [15/Mar/2024:09:17:12 +0000] "GET /api/users HTTP/1.1" 200 5120
10.0.0.50 - - [15/Mar/2024:09:18:01 +0000] "POST /login HTTP/1.1" 401 1024
192.168.1.103 - - [15/Mar/2024:09:19:33 +0000] "GET /products HTTP/1.1" 200 8192
192.168.1.101 - - [15/Mar/2024:09:20:15 +0000] "GET /cart HTTP/1.1" 200 3072
10.0.0.50 - - [15/Mar/2024:09:21:22 +0000] "POST /login HTTP/1.1" 401 1024
EOF

ARCHIVO="access_log.txt"

echo "=== GREP AVANZADO ==="

echo "Encontrar intentos de login fallidos:"
grep -E "POST /login.*401" "$ARCHIVO"

echo -e "\nIPs sospechosas (m√∫ltiples 401s):"
grep -E "POST /login.*401" "$ARCHIVO" | \
grep -oE "^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+" | \
sort | uniq -c | sort -nr

echo -e "\n=== SED PARA TRANSFORMACI√ìN ==="

echo "Extraer solo IP, hora y c√≥digo de estado:"
sed -E 's/^([0-9.]+) .*\\[([^]]+)\\].*" ([0-9]{3}).*/\\1 \\2 \\3/' "$ARCHIVO"

echo -e "\nConvertir a formato CSV:"
sed -E 's/^([0-9.]+) .*\\[([^]]+)\\].*"([^"]+)".*([0-9]{3}) ([0-9]+)/\\1,\\2,\\3,\\4,\\5/' "$ARCHIVO"

echo -e "\n=== AWK PARA AN√ÅLISIS ==="

echo "An√°lisis estad√≠stico por c√≥digo de estado:"
awk '{
    if (match($0, /" ([0-9]{3}) /, codigo)) {
        contadores[codigo[1]]++
        total++
    }
} END {
    print "üìä RESUMEN DE C√ìDIGOS DE ESTADO:"
    for (codigo in contadores) {
        porcentaje = (contadores[codigo] / total) * 100
        printf "  %s: %d requests (%.1f%%)\n", codigo, contadores[codigo], porcentaje
    }
}' "$ARCHIVO"

echo -e "\nDetecci√≥n de ataques de fuerza bruta:"
awk '{
    if (match($0, /^([0-9.]+).*POST \/login.*401/, datos)) {
        ip = datos[1]
        intentos_fallidos[ip]++
        if (intentos_fallidos[ip] >= 3) {
            if (!alertado[ip]) {
                print "üö® ALERTA: IP " ip " tiene " intentos_fallidos[ip] " intentos fallidos"
                alertado[ip] = 1
            }
        }
    }
}' "$ARCHIVO"

echo -e "\n=== PIPELINE COMPLEJO ==="

echo "Top 3 IPs por tr√°fico (bytes transferidos):"
grep -E "GET.*200" "$ARCHIVO" | \
sed -E 's/^([0-9.]+) .*" 200 ([0-9]+)/\\1 \\2/' | \
awk '{bytes[$1] += $2} END {
    for (ip in bytes) {
        print bytes[ip], ip
    }
}' | \
sort -nr | \
head -3 | \
awk '{printf "  %s: %d bytes\n", $2, $1}'

echo -e "\nHorario de mayor actividad:"
sed -E 's/.*\\[.*:([0-9]{2}):[0-9]{2}:[0-9]{2}.*/\\1/' "$ARCHIVO" | \
sort | uniq -c | sort -nr | head -1 | \
awk '{print "üïê Hora pico: " $2 ":00 con " $1 " requests"}'
```

**[PANTALLA: Ejecutando el pipeline completo]**

```bash
chmod +x regex_herramientas_bash.sh
./regex_herramientas_bash.sh
```

**[EXPLICACI√ìN FINAL DE PARTE 2]**

¬°Mira lo que acabas de lograr! Has combinado expresiones regulares con:

- **grep** para encontrar patrones complejos
- **sed** para transformar y extraer datos
- **awk** para an√°lisis estad√≠stico en tiempo real
- **pipelines** para crear soluciones sofisticadas como un verdadero profesional

Esta integraci√≥n te permite crear herramientas de an√°lisis que rivalizan con scripts de Python, pero usando solo herramientas nativas de Unix/Linux.

---

**[PANTALLA: Resumen visual de logros de Parte 2]**

¬°Incre√≠ble progreso! En estos 25 minutos has dominado:

‚úÖ **Fundamentos s√≥lidos**: Caracteres literales, metacaracteres y anclas
‚úÖ **Cuantificadores precisos**: Control exacto sobre repeticiones  
‚úÖ **Clases POSIX profesionales**: Soporte internacional robusto
‚úÖ **Grupos y capturas**: Extracci√≥n y transformaci√≥n inteligente
‚úÖ **Integraci√≥n experta**: Combinaci√≥n poderosa con grep, sed y awk

**[PANTALLA: Preview de la Parte 3]**

En la Parte 3 vamos a llevar sed y awk al siguiente nivel. Aprender√°s t√©cnicas avanzadas como el "hold space" de sed para manipulaciones multi-l√≠nea, funciones personalizadas en awk, y c√≥mo crear pipelines que pueden procesar datos tan sofisticadamente como herramientas de ciencia de datos.

¬°Nos vemos en la Parte 3, donde construiremos soluciones de nivel profesional!

---

_[Fin de la Parte 2 del gui√≥n]_

## üéØ PARTE 3: SED Y AWK AVANZADOS

### Tiempo: 50:00 - 75:00

#### [50:00 - 52:00] BIENVENIDA A LA PARTE 3 Y VISI√ìN GENERAL

**[PANTALLA: Transici√≥n animada con t√≠tulo "Parte 3: sed y awk Avanzados"]**

¬°Bienvenidos de vuelta a la Parte 3! Si has seguido las dos partes anteriores, ya tienes una base s√≥lida en arrays y expresiones regulares. Ahora vamos a integrar todo ese conocimiento en herramientas que son verdaderamente transformadoras.

**[PANTALLA: Analog√≠a visual - director de orquesta coordinando m√∫sicos]**

Imagina que eres el director de una orquesta sinf√≥nica. En las partes anteriores aprendiste a leer partituras (expresiones regulares) y a organizar instrumentos (arrays). Ahora vas a aprender a dirigir la orquesta completa, donde sed y awk son tus m√∫sicos virtuosos, cada uno con habilidades √∫nicas y complementarias.

**[PANTALLA: Comparaci√≥n visual entre herramientas b√°sicas vs avanzadas]**

Lo que veremos hoy trasciende el uso b√°sico de sed y awk:

- **sed b√°sico**: "buscar y reemplazar"
- **sed avanzado**: "memoria temporal, comandos m√∫ltiples, transformaciones complejas"
- **awk b√°sico**: "imprimir columnas"
- **awk avanzado**: "funciones personalizadas, an√°lisis estad√≠stico, mini-programas"

**[PANTALLA: Preview de lo que construiremos]**

Al final de esta parte, habr√°s creado soluciones que pueden:

- Procesar logs multi-l√≠nea complejos
- Generar reportes financieros autom√°ticos
- Detectar patrones de seguridad sofisticados
- Transformar datos como un cient√≠fico de datos

#### [52:00 - 58:00] SED AVANZADO: HOLD SPACE Y COMANDOS M√öLTIPLES

**[PANTALLA: Introducci√≥n conceptual al hold space]**

sed tiene un concepto √∫nico llamado **"hold space"** que es como tener una memoria temporal donde puedes guardar l√≠neas de texto para usarlas m√°s tarde. Es como tener un bloc de notas al lado mientras trabajas, donde anotas informaci√≥n importante para consultarla despu√©s.

**[PANTALLA: Diagrama visual del pattern space vs hold space]**

sed maneja dos espacios de memoria:

- **Pattern space**: donde procesa la l√≠nea actual
- **Hold space**: memoria temporal persistente entre l√≠neas

**[PANTALLA: Terminal preparado para ejemplos pr√°cticos]**

Vamos a crear ejemplos que demuestren el poder del hold space:

```bash
nano sed_avanzado.sh
```

```bash
#!/bin/bash
# sed_avanzado.sh - T√©cnicas avanzadas de sed
set -euo pipefail

# Creamos datos de ejemplo complejos
cat << 'EOF' > transacciones.txt
INICIO_TRANSACCION
Usuario: juan.perez
Fecha: 2024-03-15
Tipo: COMPRA
Producto: Laptop HP
Precio: 899.99
Estado: COMPLETADA
FIN_TRANSACCION

INICIO_TRANSACCION
Usuario: maria.garcia
Fecha: 2024-03-15
Tipo: DEVOLUCION
Producto: Mouse inal√°mbrico
Precio: -29.95
Estado: PROCESANDO
FIN_TRANSACCION

INICIO_TRANSACCION
Usuario: carlos.lopez
Fecha: 2024-03-16
Tipo: COMPRA
Producto: Monitor 24"
Precio: 199.00
Estado: COMPLETADA
FIN_TRANSACCION
EOF

echo "=== HOLD SPACE B√ÅSICO ==="

echo "Intercambiar l√≠neas consecutivas:"
echo -e "l√≠nea 1\nl√≠nea 2\nl√≠nea 3\nl√≠nea 4" | sed 'N;s/\(.*\)\n\(.*\)/\2\n\1/'

echo -e "\n=== ACUMULACI√ìN EN HOLD SPACE ==="

echo "Acumular todas las l√≠neas y mostrar al final:"
echo -e "primera\nsegunda\ntercera" | sed '1h;2,$H;$!d;${g;s/\n/ | /g;}'

echo -e "\n=== PROCESAMIENTO DE BLOQUES ==="

echo "Extraer solo transacciones COMPLETADAS:"
sed -n '/INICIO_TRANSACCION/,/FIN_TRANSACCION/{
    /INICIO_TRANSACCION/h
    /Usuario:/H
    /Producto:/H
    /Precio:/H
    /Estado: COMPLETADA/H
    /Estado: COMPLETADA/{
        g
        s/\n/ | /g
        p
    }
}' transacciones.txt

echo -e "\n=== COMANDOS M√öLTIPLES AVANZADOS ==="

echo "Formatear transacciones como resumen:"
sed -n '/INICIO_TRANSACCION/,/FIN_TRANSACCION/{
    /Usuario:/{
        s/Usuario: //
        h
    }
    /Producto:/{
        s/Producto: //
        H
    }
    /Precio:/{
        s/Precio: //
        H
    }
    /Estado: COMPLETADA/{
        g
        s/\n/ - /g
        s/^/‚úÖ COMPLETADA: /
        p
    }
    /Estado: PROCESANDO/{
        g
        s/\n/ - /g
        s/^/‚è≥ PROCESANDO: /
        p
    }
}' transacciones.txt

echo -e "\n=== TRANSFORMACI√ìN COMPLEJA ==="

echo "Convertir a formato CSV:"
sed -n '/INICIO_TRANSACCION/,/FIN_TRANSACCION/{
    /Usuario:/s/Usuario: //
    /Fecha:/s/Fecha: //
    /Tipo:/s/Tipo: //
    /Producto:/s/Producto: //
    /Precio:/s/Precio: //
    /Estado:/s/Estado: //
    /INICIO_TRANSACCION/{
        x
        s/.*//
        x
    }
    /Usuario:\|Fecha:\|Tipo:\|Producto:\|Precio:\|Estado:/{
        H
    }
    /FIN_TRANSACCION/{
        g
        s/\n/,/g
        s/^,//
        p
    }
}' transacciones.txt
```

**[PANTALLA: Ejecutando paso a paso con explicaciones detalladas]**

```bash
chmod +x sed_avanzado.sh
./sed_avanzado.sh
```

**[EXPLICACI√ìN MIENTRAS SE EJECUTA]**

Los comandos de hold space que acabas de ver:

- **`h`**: Copia pattern space a hold space (sobrescribe)
- **`H`**: A√±ade pattern space a hold space (acumula)
- **`g`**: Copia hold space a pattern space
- **`G`**: A√±ade hold space a pattern space
- **`x`**: Intercambia pattern space y hold space

#### [58:00 - 65:00] AWK AVANZADO: VARIABLES, FUNCIONES Y L√ìGICA COMPLEJA

**[PANTALLA: Transici√≥n conceptual a awk como lenguaje de programaci√≥n]**

Mientras que sed es como un cirujano especializado, awk es como un cient√≠fico de datos completo. No solo puede procesar texto l√≠nea por l√≠nea, sino que puede llevar registros, hacer c√°lculos complejos, mantener variables entre l√≠neas, y hasta definir sus propias funciones personalizadas.

**[PANTALLA: Arquitectura de awk: BEGIN, main, END]**

awk opera en tres fases:

1. **BEGIN**: Inicializaci√≥n (una sola vez)
2. **Main**: Procesamiento l√≠nea por l√≠nea
3. **END**: Finalizaci√≥n y reportes (una sola vez)

```bash
nano awk_avanzado.sh
```

```bash
#!/bin/bash
# awk_avanzado.sh - T√©cnicas avanzadas de awk
set -euo pipefail

# Creamos datos financieros realistas
cat << 'EOF' > ventas_datos.txt
2024-03-15,ELECTRONICA,Laptop HP,899.99,juan.perez,COMPLETADA
2024-03-15,HOGAR,Aspiradora,129.99,maria.garcia,COMPLETADA
2024-03-15,ELECTRONICA,Mouse,29.95,carlos.lopez,COMPLETADA
2024-03-16,ROPA,Camiseta,19.99,ana.rodriguez,DEVOLUCION
2024-03-16,ELECTRONICA,Monitor,199.00,luis.martin,COMPLETADA
2024-03-16,HOGAR,Cafetera,79.99,sofia.ruiz,COMPLETADA
2024-03-17,ELECTRONICA,Teclado,89.99,miguel.torres,COMPLETADA
2024-03-17,ROPA,Pantalones,49.99,elena.jimenez,COMPLETADA
2024-03-17,ELECTRONICA,Auriculares,159.99,david.morales,COMPLETADA
EOF

echo "=== VARIABLES Y CONTADORES AVANZADOS ==="

awk -F',' '
BEGIN {
    print "üìä AN√ÅLISIS DE VENTAS AVANZADO"
    print "================================"
    total_ventas = 0
    total_transacciones = 0
}

# Procesamiento principal
{
    fecha = $1
    categoria = $2
    producto = $3
    precio = $4
    vendedor = $5
    estado = $6

    # Solo procesar ventas completadas
    if (estado == "COMPLETADA") {
        # Contadores por categor√≠a
        ventas_categoria[categoria] += precio
        cantidad_categoria[categoria]++

        # Contadores por vendedor
        ventas_vendedor[vendedor] += precio
        cantidad_vendedor[vendedor]++

        # Contadores por fecha
        ventas_fecha[fecha] += precio

        # Totales generales
        total_ventas += precio
        total_transacciones++

        # Tracking del producto m√°s caro
        if (precio > precio_maximo) {
            precio_maximo = precio
            producto_mas_caro = producto
        }
    } else {
        devoluciones++
    }
}

END {
    print "\nüèÜ RESUMEN EJECUTIVO:"
    printf "   Total ventas: $%.2f\n", total_ventas
    printf "   Transacciones: %d\n", total_transacciones
    printf "   Promedio por venta: $%.2f\n", total_ventas/total_transacciones
    printf "   Producto m√°s caro: %s ($%.2f)\n", producto_mas_caro, precio_maximo
    if (devoluciones > 0) printf "   Devoluciones: %d\n", devoluciones

    print "\nüìà VENTAS POR CATEGOR√çA:"
    for (cat in ventas_categoria) {
        promedio = ventas_categoria[cat] / cantidad_categoria[cat]
        porcentaje = (ventas_categoria[cat] / total_ventas) * 100
        printf "   %-12s: $%7.2f (%2d ventas, promedio: $%.2f, %.1f%%)\n",
               cat, ventas_categoria[cat], cantidad_categoria[cat], promedio, porcentaje
    }

    print "\nüë• TOP 3 VENDEDORES:"
    # Crear array ordenado por ventas
    n = asorti(ventas_vendedor, vendedores_ordenados)
    for (i = n; i >= n-2 && i >= 1; i--) {
        vendedor = vendedores_ordenados[i]
        printf "   %d. %-15s: $%7.2f (%d ventas)\n",
               n-i+1, vendedor, ventas_vendedor[vendedor], cantidad_vendedor[vendedor]
    }

    print "\nüìÖ VENTAS POR D√çA:"
    for (fecha in ventas_fecha) {
        printf "   %s: $%.2f\n", fecha, ventas_fecha[fecha]
    }
}' ventas_datos.txt

echo -e "\n=== FUNCIONES PERSONALIZADAS ==="

awk -F',' '
# Funci√≥n para formatear moneda
function formatear_moneda(cantidad) {
    return sprintf("$%,.2f", cantidad)
}

# Funci√≥n para categorizar precio
function categorizar_precio(precio) {
    if (precio < 50) return "BAJO"
    else if (precio < 200) return "MEDIO"
    else return "ALTO"
}

# Funci√≥n para calcular comisi√≥n
function calcular_comision(precio, categoria) {
    if (categoria == "ELECTRONICA") return precio * 0.05
    else if (categoria == "HOGAR") return precio * 0.03
    else return precio * 0.02
}

BEGIN {
    print "üßÆ AN√ÅLISIS CON FUNCIONES PERSONALIZADAS"
    print "========================================"
}

$6 == "COMPLETADA" {
    precio = $4
    categoria = $2
    vendedor = $5

    categoria_precio = categorizar_precio(precio)
    comision = calcular_comision(precio, categoria)

    printf "%-20s | %-12s | %s | %-5s | Comisi√≥n: %s\n",
           $3, categoria, formatear_moneda(precio), categoria_precio, formatear_moneda(comision)

    total_comisiones += comision
}

END {
    print "\nüí∞ TOTAL COMISIONES: " formatear_moneda(total_comisiones)
}' ventas_datos.txt

echo -e "\n=== AN√ÅLISIS ESTAD√çSTICO AVANZADO ==="

awk -F',' '
BEGIN {
    print "üìä AN√ÅLISIS ESTAD√çSTICO DETALLADO"
    print "================================="
}

$6 == "COMPLETADA" {
    precios[NR] = $4
    suma += $4
    suma_cuadrados += ($4 * $4)
    n++

    # Para calcular mediana
    if (n == 1) {
        min = max = $4
    } else {
        if ($4 < min) min = $4
        if ($4 > max) max = $4
    }
}

END {
    if (n > 0) {
        media = suma / n
        varianza = (suma_cuadrados / n) - (media * media)
        desviacion = sqrt(varianza)

        print "\nüìà ESTAD√çSTICAS DESCRIPTIVAS:"
        printf "   Transacciones analizadas: %d\n", n
        printf "   Media: $%.2f\n", media
        printf "   M√≠nimo: $%.2f\n", min
        printf "   M√°ximo: $%.2f\n", max
        printf "   Rango: $%.2f\n", max - min
        printf "   Desviaci√≥n est√°ndar: $%.2f\n", desviacion
        printf "   Coeficiente de variaci√≥n: %.2f%%\n", (desviacion/media)*100

        # An√°lisis de distribuci√≥n
        bajo = medio = alto = 0
        for (i = 1; i <= n; i++) {
            if (precios[i] < media - desviacion) bajo++
            else if (precios[i] > media + desviacion) alto++
            else medio++
        }

        print "\nüìä DISTRIBUCI√ìN DE PRECIOS:"
        printf "   Bajo (< $%.2f): %d (%.1f%%)\n", media-desviacion, bajo, (bajo/n)*100
        printf "   Medio: %d (%.1f%%)\n", medio, (medio/n)*100
        printf "   Alto (> $%.2f): %d (%.1f%%)\n", media+desviacion, alto, (alto/n)*100
    }
}' ventas_datos.txt
```

**[PANTALLA: Ejecutando con explicaciones profundas]**

```bash
chmod +x awk_avanzado.sh
./awk_avanzado.sh
```

**[EXPLICACI√ìN T√âCNICA AVANZADA]**

Lo que acabas de ver representa t√©cnicas de nivel profesional:

1. **Arrays asociativos multidimensionales** para an√°lisis por categor√≠a y vendedor
2. **Funciones personalizadas** que encapsulan l√≥gica compleja
3. **An√°lisis estad√≠stico** con c√°lculos de media, varianza y desviaci√≥n est√°ndar
4. **Formateo profesional** con alineaci√≥n y moneda
5. **L√≥gica condicional compleja** para categorizaci√≥n autom√°tica

#### [65:00 - 72:00] CASOS DE USO PR√ÅCTICOS - INTEGRANDO TODO

**[PANTALLA: Transici√≥n a casos de uso del mundo real]**

Ahora que dominas las t√©cnicas avanzadas tanto de sed como de awk, vamos a ver c√≥mo estas herramientas trabajan juntas para resolver problemas reales que encontrar√≠as en un entorno profesional.

```bash
nano casos_practicos_avanzados.sh
```

```bash
#!/bin/bash
# casos_practicos_avanzados.sh - Soluciones reales integradas
set -euo pipefail

echo "=== CASO 1: AN√ÅLISIS DE LOGS DE SEGURIDAD ==="

# Creamos logs de seguridad realistas
cat << 'EOF' > security.log
2024-03-15 09:15:30 [SECURITY] LOGIN_SUCCESS user=admin ip=192.168.1.100 session=abc123
2024-03-15 09:16:45 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:17:12 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:18:01 [SECURITY] LOGIN_FAILED user=admin ip=10.0.0.50 reason=invalid_password
2024-03-15 09:19:33 [SECURITY] FILE_ACCESS user=admin file=/etc/passwd action=read
2024-03-15 09:20:15 [SECURITY] LOGIN_SUCCESS user=operator ip=192.168.1.101 session=def456
2024-03-15 09:21:22 [SECURITY] LOGIN_FAILED user=guest ip=10.0.0.50 reason=invalid_password
2024-03-15 09:22:45 [SECURITY] PERMISSION_DENIED user=operator file=/root/secret.txt
2024-03-15 09:23:12 [SECURITY] LOGOUT user=admin session=abc123
EOF

echo "Pipeline completo: sed para normalizar + awk para analizar"

sed -E 's/\[SECURITY\] //g' security.log | \
awk '
BEGIN {
    print "üîí AN√ÅLISIS DE SEGURIDAD AUTOM√ÅTICO"
    print "==================================="
}

/LOGIN_FAILED/ {
    match($0, /ip=([0-9]+)/, ip_match)
    match($0, /user=([^ ]+)/, user_match)

    if (ip_match[1] && user_match[1]) {
        intentos_fallidos[ip_match[1]]++
        usuarios_atacados[user_match[1]]++
        total_fallos++

        # Detectar ataques de fuerza bruta
        if (intentos_fallidos[ip_match[1]] >= 3) {
            if (!alertado[ip_match[1]]) {
                print "üö® ALERTA: Posible ataque de fuerza bruta desde " ip_match[1]
                alertado[ip_match[1]] = 1
            }
        }
    }
}

/LOGIN_SUCCESS/ {
    match($0, /user=([^ ]+)/, user_match)
    if (user_match[1]) {
        logins_exitosos[user_match[1]]++
    }
}

/PERMISSION_DENIED/ {
    match($0, /user=([^ ]+)/, user_match)
    match($0, /file=([^ ]+)/, file_match)
    if (user_match[1] && file_match[1]) {
        print "‚ö†Ô∏è  ACCESO DENEGADO: " user_match[1] " intent√≥ acceder a " file_match[1]
        accesos_denegados++
    }
}

END {
    print "\nüìä RESUMEN DE SEGURIDAD:"
    printf "   Total intentos fallidos: %d\n", total_fallos
    printf "   Accesos denegados: %d\n", accesos_denegados

    print "\nüéØ IPs SOSPECHOSAS:"
    for (ip in intentos_fallidos) {
        if (intentos_fallidos[ip] >= 2) {
            printf "   %s: %d intentos fallidos\n", ip, intentos_fallidos[ip]
        }
    }

    print "\nüë• USUARIOS M√ÅS ATACADOS:"
    for (user in usuarios_atacados) {
        printf "   %s: %d intentos\n", user, usuarios_atacados[user]
    }
}'

echo -e "\n=== CASO 2: PROCESAMIENTO DE DATOS FINANCIEROS ==="

# Datos financieros complejos
cat << 'EOF' > transacciones_financieras.txt
HEADER|REPORTE_DIARIO|2024-03-15
CUENTA|12345|Juan P√©rez|ACTIVA
TRANSACCION|12345|2024-03-15 09:15|DEPOSITO|500.00|N√≥mina marzo
TRANSACCION|12345|2024-03-15 10:30|RETIRO|-150.00|Cajero autom√°tico
TRANSACCION|12345|2024-03-15 14:45|COMPRA|-89.99|Amazon.com
CUENTA|67890|Mar√≠a Garc√≠a|ACTIVA
TRANSACCION|67890|2024-03-15 08:00|DEPOSITO|1200.00|Freelance trabajo
TRANSACCION|67890|2024-03-15 11:15|TRANSFERENCIA|-300.00|Pago alquiler
TRANSACCION|67890|2024-03-15 16:20|COMPRA|-45.50|Supermercado
CUENTA|54321|Carlos L√≥pez|SUSPENDIDA
TRANSACCION|54321|2024-03-15 12:00|INTENTO_RETIRO|-200.00|RECHAZADO
FOOTER|TOTAL_CUENTAS|3|TOTAL_TRANSACCIONES|8
EOF

echo "Procesamiento complejo: an√°lisis por cuenta con estados"

# Primero normalizamos con sed, luego analizamos con awk
sed -E '
    # Limpiar headers y footers
    /^HEADER|^FOOTER/d
    # Separar informaci√≥n de cuenta de transacciones
    s/^CUENTA\|([0-9]+)\|([^|]+)\|(.+)/CUENTA:\1:\2:\3/
    s/^TRANSACCION\|([0-9]+)\|([^|]+)\|([^|]+)\|([0-9.-]+)\|(.+)/TRANS:\1:\2:\3:\4:\5/
' transacciones_financieras.txt | \
awk -F':' '
BEGIN {
    print "üí∞ AN√ÅLISIS FINANCIERO AUTOMATIZADO"
    print "===================================="
}

# Procesar informaci√≥n de cuenta
/^CUENTA/ {
    cuenta_id = $2
    nombre = $3
    estado = $4

    cuentas[cuenta_id] = nombre
    estados[cuenta_id] = estado
    saldo[cuenta_id] = 0
    transacciones_cuenta[cuenta_id] = 0
}

/^TRANS/ {
    cuenta_id = $2
    fecha_hora = $3
    tipo = $4
    monto = $5
    concepto = $6

    if (estados[cuenta_id] == "ACTIVA") {
        saldo[cuenta_id] += monto
        transacciones_cuenta[cuenta_id]++

        # Categorizar transacciones
        if (monto > 0) {
            ingresos[cuenta_id] += monto
            total_ingresos += monto
        } else {
            gastos[cuenta_id] += (-monto)
            total_gastos += (-monto)

            # Detectar gastos grandes
            if (-monto > 100) {
                print "üí≥ GASTO GRANDE: " cuentas[cuenta_id] " gast√≥ $" (-monto) " en " concepto
            }
        }

        # An√°lisis por tipo
        tipos_transaccion[tipo]++
    } else {
        print "üö´ TRANSACCI√ìN RECHAZADA: Cuenta " cuenta_id " (" cuentas[cuenta_id] ") est√° " estados[cuenta_id]
        rechazadas++
    }
}

END {
    print "\nüìà RESUMEN POR CUENTA:"
    for (cuenta in cuentas) {
        printf "   %s (%s):\n", cuentas[cuenta], cuenta
        printf "     Estado: %s\n", estados[cuenta]
        if (estados[cuenta] == "ACTIVA") {
            printf "     Saldo: $%.2f\n", saldo[cuenta]
            printf "     Transacciones: %d\n", transacciones_cuenta[cuenta]
            printf "     Ingresos: $%.2f\n", ingresos[cuenta]
            printf "     Gastos: $%.2f\n", gastos[cuenta]

            if (saldo[cuenta] < 0) {
                print "     ‚ö†Ô∏è  SALDO NEGATIVO"
            }
        }
        print ""
    }

    print "üíº RESUMEN GENERAL:"
    printf "   Total ingresos: $%.2f\n", total_ingresos
    printf "   Total gastos: $%.2f\n", total_gastos
    printf "   Flujo neto: $%.2f\n", total_ingresos - total_gastos
    if (rechazadas > 0) printf "   Transacciones rechazadas: %d\n", rechazadas

    print "\nüìä TIPOS DE TRANSACCI√ìN:"
    for (tipo in tipos_transaccion) {
        printf "   %-15s: %d\n", tipo, tipos_transaccion[tipo]
    }
}'

echo -e "\n=== CASO 3: MONITOREO DE SISTEMA EN TIEMPO REAL ==="

# Simulamos datos de sistema
cat << 'EOF' > system_metrics.txt
2024-03-15 09:15:30|CPU|75.5|%|server01
2024-03-15 09:15:30|MEMORY|8.2|GB|server01
2024-03-15 09:15:30|DISK|45.8|%|server01
2024-03-15 09:15:30|NETWORK_RX|1250|KB/s|server01
2024-03-15 09:15:30|NETWORK_TX|890|KB/s|server01
2024-03-15 09:16:30|CPU|82.1|%|server01
2024-03-15 09:16:30|MEMORY|8.9|GB|server01
2024-03-15 09:16:30|DISK|46.2|%|server01
2024-03-15 09:17:30|CPU|95.8|%|server01
2024-03-15 09:17:30|MEMORY|12.1|GB|server01
2024-03-15 09:17:30|DISK|47.1|%|server01
EOF

echo "Monitoreo inteligente con alertas autom√°ticas:"

awk -F'|' '
BEGIN {
    print "üñ•Ô∏è  MONITOREO DE SISTEMA INTELIGENTE"
    print "===================================="

    # Umbrales de alerta
    umbral_cpu = 90
    umbral_memory = 10
    umbral_disk = 80
}

{
    timestamp = $1
    metrica = $2
    valor = $3
    unidad = $4
    servidor = $5

    # Almacenar √∫ltima medici√≥n
    ultimas_metricas[servidor "_" metrica] = valor
    servidores[servidor] = 1

    # Detectar alertas
    if (metrica == "CPU" && valor > umbral_cpu) {
        print "üî• ALERTA CPU: " servidor " al " valor "% (umbral: " umbral_cpu "%)"
        alertas_cpu++
    }

    if (metrica == "MEMORY" && valor > umbral_memory) {
        print "üß† ALERTA MEMORIA: " servidor " usando " valor "GB (umbral: " umbral_memory "GB)"
        alertas_memory++
    }

    if (metrica == "DISK" && valor > umbral_disk) {
        print "üíæ ALERTA DISCO: " servidor " al " valor "% (umbral: " umbral_disk "%)"
        alertas_disk++
    }

    # Acumular para promedios
    suma_metricas[metrica] += valor
    count_metricas[metrica]++
}

END {
    print "\nüìä ESTADO ACTUAL DEL SISTEMA:"
    for (servidor in servidores) {
        printf "\nüñ•Ô∏è  %s:\n", servidor
        printf "   CPU: %.1f%%\n", ultimas_metricas[servidor "_CPU"]
        printf "   Memoria: %.1fGB\n", ultimas_metricas[servidor "_MEMORY"]
        printf "   Disco: %.1f%%\n", ultimas_metricas[servidor "_DISK"]

        # Estado general del servidor
        cpu_val = ultimas_metricas[servidor "_CPU"]
        mem_val = ultimas_metricas[servidor "_MEMORY"]
        disk_val = ultimas_metricas[servidor "_DISK"]

        if (cpu_val > 90 || mem_val > 10 || disk_val >  80) {
            print "   üö® ESTADO: CR√çTICO"
        } else if (cpu_val > 70 || mem_val > 8 || disk_val > 60) {
            print "   ‚ö†Ô∏è  ESTADO: ADVERTENCIA"
        } else {
            print "   ‚úÖ ESTADO: NORMAL"
        }
    }

    print "\nüìà PROMEDIOS HIST√ìRICOS:"
    for (metrica in suma_metricas) {
        promedio = suma_metricas[metrica] / count_metricas[metrica]
        printf "   %-10s: %.1f\n", metrica, promedio
    }

    if (alertas_cpu + alertas_memory + alertas_disk > 0) {
        print "\nüö® RESUMEN DE ALERTAS:"
        if (alertas_cpu > 0) printf "   CPU: %d alertas\n", alertas_cpu
        if (alertas_memory > 0) printf "   Memoria: %d alertas\n", alertas_memory
        if (alertas_disk > 0) printf "   Disco: %d alertas\n", alertas_disk
    } else {
        print "\n‚úÖ Sin alertas activas"
    }
}' system_metrics.txt
```

**[PANTALLA: Ejecutando la demostraci√≥n completa]**

```bash
chmod +x casos_practicos_avanzados.sh
./casos_practicos_avanzados.sh
```

**[EXPLICACI√ìN DE NIVEL EMPRESARIAL]**

Lo que acabas de ver son soluciones de nivel profesional que podr√≠as implementar inmediatamente en un entorno empresarial:

1. **An√°lisis de seguridad**: Detecci√≥n autom√°tica de ataques de fuerza bruta
2. **Procesamiento financiero**: An√°lisis de flujo de efectivo con alertas
3. **Monitoreo de sistemas**: Dashboard en tiempo real con umbrales inteligentes

#### [72:00 - 75:00] S√çNTESIS Y PREPARACI√ìN PARA EL PROYECTO

**[PANTALLA: Transici√≥n hacia la integraci√≥n final]**

¬°Incre√≠ble! Has completado las tres lecciones fundamentales del M√≥dulo 5. Has construido una base extraordinariamente s√≥lida que integra:

‚úÖ **Arrays complejos** para organizar datos multidimensionales
‚úÖ **Expresiones regulares expertas** para extracci√≥n precisa de patrones
‚úÖ **sed avanzado** con hold space para transformaciones complejas
‚úÖ **awk profesional** con funciones y an√°lisis estad√≠stico

**[PANTALLA: Visualizaci√≥n de la progresi√≥n del aprendizaje]**

Piensa en el viaje que has completado:

- **M√≥dulo 1-2**: Fundamentos y herramientas b√°sicas
- **M√≥dulo 3-4**: Control de flujo y organizaci√≥n del c√≥digo
- **M√≥dulo 5**: Manipulaci√≥n avanzada de datos (¬°donde est√°s ahora!)

**[PANTALLA: Preview del proyecto final]**

Ahora llega el momento de la s√≠ntesis: el **Proyecto Pr√°ctico 5 - Analizador de Logs Profesional**. Este proyecto integrar√° todo lo que has aprendido en una herramienta real que podr√≠as usar en tu trabajo ma√±ana mismo.

El analizador que construir√°s ser√° capaz de:

- Procesar logs de Apache, Nginx, aplicaciones personalizadas
- Detectar anomal√≠as de seguridad autom√°ticamente
- Generar reportes ejecutivos con gr√°ficos HTML
- Crear alertas inteligentes basadas en patrones
- Producir an√°lisis estad√≠stico profesional

**[PANTALLA: Estad√≠sticas de transformaci√≥n personal]**

En estas primeras 75 minutos has:

- Ejecutado m√°s de 15 scripts avanzados
- Procesado datasets complejos de m√∫ltiples dominios
- Implementado algoritmos de an√°lisis de datos
- Creado soluciones que rivalizan con herramientas comerciales

**[PANTALLA: Transici√≥n motivacional hacia el proyecto]**

La diferencia entre conocer t√©cnicas individuales y ser capaz de crear soluciones integrales es exactamente lo que vamos a desarrollar en los pr√≥ximos 45 minutos. El proyecto final es donde todo "hace click" definitivamente.

¬øEst√°s listo para construir algo verdaderamente impresionante?

---

**[PANTALLA: Resumen visual de logros de Parte 3]**

üéØ **LOGROS DE LA PARTE 3:**

‚úÖ **sed avanzado**: Hold space, comandos m√∫ltiples, transformaciones complejas
‚úÖ **awk profesional**: Variables globales, funciones personalizadas, an√°lisis estad√≠stico
‚úÖ **Casos reales**: Seguridad, finanzas, monitoreo de sistemas
‚úÖ **Integraci√≥n experta**: Pipelines sofisticados que combinan m√∫ltiples herramientas

**[PANTALLA: Call to action para la Parte 4]**

En la Parte 4 final, construiremos el **Analizador de Logs m√°s sofisticado** que hayas visto en bash. Ser√° tu obra maestra del M√≥dulo 5, una herramienta que podr√°s mostrar con orgullo como ejemplo de tus habilidades t√©cnicas.

¬°Nos vemos en la Parte 4 para el gran finale!

---

_[Fin de la Parte 3 del gui√≥n]_

## üéØ PARTE 4A: PROYECTO PR√ÅCTICO - DISE√ëO Y ARQUITECTURA

### Tiempo: 75:00 - 90:00

#### [75:00 - 77:00] BIENVENIDA AL PROYECTO FINAL

**[PANTALLA: Transici√≥n √©pica con t√≠tulo "Parte 4: Proyecto Pr√°ctico - Analizador de Logs"]**

¬°Bienvenidos al momento m√°s emocionante de todo el M√≥dulo 5! Durante las √∫ltimas tres partes has construido una base t√©cnica extraordinaria. Ahora llega el momento de la s√≠ntesis: crear una herramienta profesional que integre todo tu conocimiento en una soluci√≥n real.

**[PANTALLA: Visi√≥n del proyecto completado - screenshots del analizador funcionando]**

El analizador de logs que vamos a construir no es un ejercicio acad√©mico. Es una herramienta de nivel empresarial que podr√≠as:

- **Implementar ma√±ana mismo** en tu trabajo actual
- **Mostrar en una entrevista** como ejemplo de tus habilidades
- **Usar como base** para proyectos m√°s complejos
- **Presentar a tu equipo** para impresionar a colegas y jefes

**[PANTALLA: Estad√≠sticas de impacto del proyecto]**

Al completar este proyecto, habr√°s demostrado maestr√≠a en:

- Arquitectura modular de software
- Procesamiento de datos en tiempo real
- An√°lisis estad√≠stico automatizado
- Detecci√≥n de anomal√≠as de seguridad
- Generaci√≥n de reportes ejecutivos
- Optimizaci√≥n de rendimiento

#### [77:00 - 80:00] VISI√ìN Y ALCANCE DEL PROYECTO

**[PANTALLA: Escenario empresarial realista]**

**EL ESCENARIO:**
Trabajas como DevOps Engineer en una empresa que maneja m√∫ltiples servicios: servidores web, bases de datos, aplicaciones, APIs. Cada d√≠a se generan millones de l√≠neas de logs que contienen informaci√≥n cr√≠tica sobre rendimiento, seguridad, y salud del sistema.

**EL PROBLEMA:**
Actualmente, cuando surge un incidente:

- Los equipos revisan logs manualmente (lento y propenso a errores)
- Los patrones importantes pasan desapercibidos
- La detecci√≥n de problemas es reactiva, no proactiva
- No hay visibilidad ejecutiva del estado del sistema

**[PANTALLA: Arquitectura de la soluci√≥n que construiremos]**

**LA SOLUCI√ìN:**
Tu analizador de logs ser√° capaz de:

1. **Procesamiento Multi-formato**: Apache, Nginx, aplicaciones personalizadas, syslog
2. **An√°lisis Inteligente**: Detecci√≥n de anomal√≠as, patrones de seguridad, m√©tricas de rendimiento
3. **Alertas Autom√°ticas**: Notificaciones proactivas de problemas cr√≠ticos
4. **Reportes Ejecutivos**: Dashboards HTML con gr√°ficos y m√©tricas clave
5. **Escalabilidad**: Manejo eficiente de archivos de GB de tama√±o

**[PANTALLA: Demostraci√≥n del flujo de trabajo completo]**

**FLUJO DE TRABAJO:**

```
Logs Raw ‚Üí Normalizaci√≥n ‚Üí An√°lisis ‚Üí Detecci√≥n ‚Üí Reportes ‚Üí Alertas
   ‚Üì            ‚Üì           ‚Üì          ‚Üì          ‚Üì        ‚Üì
Multiple    Standard    Pattern    Anomaly    HTML     Email/
Formats     Format      Mining     Detection  Reports  Slack
```

#### [80:00 - 85:00] ARQUITECTURA MODULAR PROFESIONAL

**[PANTALLA: Diagrama de componentes del sistema]**

Vamos a dise√±ar nuestro analizador con una arquitectura modular profesional. Cada componente tiene una responsabilidad espec√≠fica y puede evolucionar independientemente.

**[PANTALLA: Creando la estructura del proyecto]**

```bash
# Creamos la estructura del proyecto
mkdir -p log_analyzer/{modules,config,data,reports,tests}
cd log_analyzer

echo "üìÅ ESTRUCTURA DEL PROYECTO:"
echo "=========================="
tree .
```

**[PANTALLA: Escribiendo el script principal]**

```bash
nano log_analyzer.sh
```

```bash
#!/bin/bash
# log_analyzer.sh - Analizador de Logs Profesional
# M√≥dulo 5 - Bootcamp Bash Scripting
# Arquitectura modular para an√°lisis empresarial de logs

set -euo pipefail

# =============================================================================
# CONFIGURACI√ìN GLOBAL Y CONSTANTES
# =============================================================================

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly MODULES_DIR="${SCRIPT_DIR}/modules"
readonly CONFIG_DIR="${SCRIPT_DIR}/config"
readonly DATA_DIR="${SCRIPT_DIR}/data"
readonly REPORTS_DIR="${SCRIPT_DIR}/reports"

# Colores para output
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly PURPLE='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly NC='\033[0m' # No Color

# Configuraci√≥n por defecto
declare -A CONFIG=(
    ["alert_threshold_error_rate"]="10"
    ["alert_threshold_response_time"]="2.0"
    ["alert_threshold_failed_logins"]="5"
    ["report_format"]="html"
    ["max_file_size_mb"]="500"
    ["retention_days"]="30"
)

# Arrays para estad√≠sticas globales
declare -A GLOBAL_STATS
declare -A ALERT_SUMMARY
declare -A PERFORMANCE_METRICS

# =============================================================================
# FUNCIONES UTILITARIAS
# =============================================================================

log_message() {
    local level="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')

    case "$level" in
        "INFO")  echo -e "${CYAN}[INFO]${NC}  ${timestamp} - $message" ;;
        "WARN")  echo -e "${YELLOW}[WARN]${NC}  ${timestamp} - $message" ;;
        "ERROR") echo -e "${RED}[ERROR]${NC} ${timestamp} - $message" ;;
        "SUCCESS") echo -e "${GREEN}[OK]${NC}    ${timestamp} - $message" ;;
    esac
}

validate_file() {
    local file="$1"

    if [[ ! -f "$file" ]]; then
        log_message "ERROR" "Archivo no encontrado: $file"
        return 1
    fi

    local size_mb=$(( $(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo 0) / 1024 / 1024 ))

    if [[ $size_mb -gt ${CONFIG[max_file_size_mb]} ]]; then
        log_message "WARN" "Archivo muy grande: ${size_mb}MB (m√°ximo: ${CONFIG[max_file_size_mb]}MB)"
        read -p "¬øContinuar de todos modos? (y/N): " -n 1 -r
        echo
        [[ $REPLY =~ ^[Yy]$ ]] || return 1
    fi

    return 0
}

create_output_directory() {
    local dir="$1"

    if [[ ! -d "$dir" ]]; then
        mkdir -p "$dir" || {
            log_message "ERROR" "No se pudo crear directorio: $dir"
            return 1
        }
        log_message "INFO" "Directorio creado: $dir"
    fi
}

# =============================================================================
# CARGA DE M√ìDULOS
# =============================================================================

load_module() {
    local module_name="$1"
    local module_path="${MODULES_DIR}/${module_name}.sh"

    if [[ -f "$module_path" ]]; then
        source "$module_path"
        log_message "INFO" "M√≥dulo cargado: $module_name"
    else
        log_message "ERROR" "M√≥dulo no encontrado: $module_path"
        return 1
    fi
}

# =============================================================================
# FUNCI√ìN PRINCIPAL DE AN√ÅLISIS
# =============================================================================

analyze_log_file() {
    local input_file="$1"
    local output_prefix="$2"

    log_message "INFO" "Iniciando an√°lisis de: $(basename "$input_file")"

    # Validar archivo de entrada
    validate_file "$input_file" || return 1

    # Crear directorio de salida
    create_output_directory "$REPORTS_DIR" || return 1

    # Detectar formato de log
    local log_format
    log_format=$(detect_log_format "$input_file")
    log_message "INFO" "Formato detectado: $log_format"

    # Normalizar datos
    local normalized_file="${DATA_DIR}/normalized_${output_prefix}.log"
    normalize_log_file "$input_file" "$normalized_file" "$log_format"

    # An√°lisis de patrones
    local analysis_file="${DATA_DIR}/analysis_${output_prefix}.json"
    analyze_patterns "$normalized_file" "$analysis_file"

    # Detecci√≥n de anomal√≠as
    local alerts_file="${DATA_DIR}/alerts_${output_prefix}.json"
    detect_anomalies "$normalized_file" "$alerts_file"

    # Generaci√≥n de reportes
    local report_file="${REPORTS_DIR}/report_${output_prefix}.html"
    generate_report "$analysis_file" "$alerts_file" "$report_file"

    log_message "SUCCESS" "An√°lisis completado. Reporte: $report_file"
}

# =============================================================================
# GESTI√ìN DE CONFIGURACI√ìN
# =============================================================================

load_config() {
    local config_file="${CONFIG_DIR}/analyzer.conf"

    if [[ -f "$config_file" ]]; then
        log_message "INFO" "Cargando configuraci√≥n desde: $config_file"

        while IFS='=' read -r key value; do
            # Ignorar comentarios y l√≠neas vac√≠as
            [[ "$key" =~ ^#.*$ || -z "$key" ]] && continue

            # Limpiar espacios
            key=$(echo "$key" | tr -d ' ')
            value=$(echo "$value" | tr -d ' ')

            CONFIG["$key"]="$value"
        done < "$config_file"
    else
        log_message "WARN" "Archivo de configuraci√≥n no encontrado, usando valores por defecto"
    fi
}

show_config() {
    log_message "INFO" "Configuraci√≥n actual:"
    for key in "${!CONFIG[@]}"; do
        printf "  %-30s: %s\n" "$key" "${CONFIG[$key]}"
    done
}

# =============================================================================
# MANEJO DE ARGUMENTOS Y MENU PRINCIPAL
# =============================================================================

show_usage() {
    cat << EOF
${BLUE}
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    ANALIZADOR DE LOGS PROFESIONAL v2.0                      ‚ïë
‚ïë                         Bootcamp Bash Scripting                             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
${NC}

USAGE: $0 [OPTIONS] [LOG_FILE]

OPTIONS:
    -f, --file FILE         Archivo de log a analizar
    -o, --output PREFIX     Prefijo para archivos de salida
    -c, --config FILE       Archivo de configuraci√≥n personalizado
    -t, --threshold NUM     Umbral personalizado para alertas
    -r, --report FORMAT     Formato de reporte (html|json|text)
    -v, --verbose           Modo verbose
    -h, --help              Mostrar esta ayuda
    --demo                  Ejecutar demostraci√≥n con datos de ejemplo
    --config-show           Mostrar configuraci√≥n actual

EXAMPLES:
    $0 --file /var/log/apache2/access.log
    $0 --file app.log --output myapp --report html
    $0 --demo
    $0 --config-show

FORMATOS SOPORTADOS:
    ‚Ä¢ Apache Combined Log Format
    ‚Ä¢ Nginx Access Logs
    ‚Ä¢ Application Logs (JSON/Plain)
    ‚Ä¢ Syslog Format
    ‚Ä¢ Custom formats (configurables)

EOF
}

main() {
    # Banner de bienvenida
    cat << EOF
${PURPLE}
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üöÄ ANALIZADOR DE LOGS PROFESIONAL - INICIANDO                              ‚ïë
‚ïë  üìä M√≥dulo 5: Manipulaci√≥n Avanzada de Datos                               ‚ïë
‚ïë  üéØ Bootcamp Bash Scripting                                                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
${NC}

EOF

    # Cargar configuraci√≥n
    load_config

    # Variables locales
    local input_file=""
    local output_prefix="analysis_$(date +%Y%m%d_%H%M%S)"
    local verbose=false
    local demo_mode=false

    # Procesar argumentos
    while [[ $# -gt 0 ]]; do
        case $1 in
            -f|--file)
                input_file="$2"
                shift 2
                ;;
            -o|--output)
                output_prefix="$2"
                shift 2
                ;;
            -c|--config)
                CONFIG_FILE="$2"
                load_config
                shift 2
                ;;
            -r|--report)
                CONFIG["report_format"]="$2"
                shift 2
                ;;
            -v|--verbose)
                verbose=true
                shift
                ;;
            --demo)
                demo_mode=true
                shift
                ;;
            --config-show)
                show_config
                exit 0
                ;;
            -h|--help)
                show_usage
                exit 0
                ;;
            *)
                log_message "ERROR" "Opci√≥n desconocida: $1"
                show_usage
                exit 1
                ;;
        esac
    done

    # Cargar m√≥dulos necesarios
    load_module "log_normalizer"
    load_module "pattern_analyzer"
    load_module "anomaly_detector"
    load_module "report_generator"

    # Ejecutar seg√∫n modo
    if [[ "$demo_mode" == true ]]; then
        log_message "INFO" "Ejecutando modo demostraci√≥n..."
        run_demo
    elif [[ -n "$input_file" ]]; then
        analyze_log_file "$input_file" "$output_prefix"
    else
        log_message "ERROR" "Debe especificar un archivo de log o usar --demo"
        show_usage
        exit 1
    fi
}

# Ejecutar funci√≥n principal si el script se ejecuta directamente
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
```

**[PANTALLA: Explicando la arquitectura mientras se escribe]**

Lo que acabas de ver es una arquitectura de software profesional aplicada a bash:

1. **Separaci√≥n de responsabilidades**: Cada m√≥dulo tiene un prop√≥sito espec√≠fico
2. **Configuraci√≥n centralizada**: Par√°metros ajustables sin modificar c√≥digo
3. **Logging estructurado**: Mensajes claros con niveles y timestamps
4. **Validaci√≥n robusta**: Verificaci√≥n de archivos y par√°metros
5. **Manejo de errores**: Fallos controlados con mensajes informativos
6. **Interfaz profesional**: CLI con opciones completas y ayuda

#### [85:00 - 90:00] CREACI√ìN DE M√ìDULOS FUNDAMENTALES

**[PANTALLA: Creando el primer m√≥dulo - Normalizador de Logs]**

Ahora vamos a construir los m√≥dulos especializados. Empezamos con el normalizador, que es el coraz√≥n del sistema.

```bash
nano modules/log_normalizer.sh
```

```bash
#!/bin/bash
# modules/log_normalizer.sh - Normalizador de logs multi-formato
# Convierte diferentes formatos de log a un formato est√°ndar para an√°lisis

# =============================================================================
# DETECTORES DE FORMATO
# =============================================================================

detect_log_format() {
    local file="$1"
    local sample_lines=10

    # Obtener muestra del archivo
    local sample
    sample=$(head -n "$sample_lines" "$file")

    # Patrones de detecci√≥n
    if grep -qE '^\[.*\] - - \[.*\] ".*" [0-9]{3} [0-9]+' <<< "$sample"; then
        echo "apache_combined"
    elif grep -qE '^[0-9.]+ - - \[.*\] ".*" [0-9]{3}' <<< "$sample"; then
        echo "apache_common"
    elif grep -qE '^[0-9.]+ - .* \[.*\] ".*" [0-9]{3} [0-9]+ ".*" ".*"' <<< "$sample"; then
        echo "nginx_combined"
    elif grep -qE '^[A-Z][a-z]{2} [0-9 :]+ [a-zA-Z0-9.-]+ ' <<< "$sample"; then
        echo "syslog"
    elif grep -qE '^\{.*\}$' <<< "$sample"; then
        echo "json"
    elif grep -qE '^[0-9]{4}-[0-9]{2}-[0-9]{2}.*\[(INFO|WARN|ERROR|DEBUG)\]' <<< "$sample"; then
        echo "application"
    else
        echo "unknown"
    fi
}

# =============================================================================
# NORMALIZADORES POR FORMATO
# =============================================================================

normalize_apache_combined() {
    local input="$1"
    local output="$2"

    log_message "INFO" "Normalizando formato Apache Combined..."

    sed -E '
        # Extraer campos del formato Apache Combined
        # 127.0.0.1 - - [10/Oct/2000:13:55:36 -0700] "GET /apache_pb.gif HTTP/1.0" 200 2326
        s/^([0-9.]+) - - \[([^\]]+)\] "([A-Z]+) ([^ ]+) ([^"]+)" ([0-9]{3}) ([0-9]+).*$/\2|\1|INFO|Apache|\3 \4|\6|\7|/

        # Convertir timestamp Apache a formato est√°ndar
        s/([0-9]{2})\/([A-Z][a-z]{2})\/([0-9]{4}):([0-9:]+) [+-][0-9]{4}/\3-\2-\1 \4/

        # Convertir nombres de mes
        s/-Jan-/-01-/g; s/-Feb-/-02-/g; s/-Mar-/-03-/g; s/-Apr-/-04-/g
        s/-May-/-05-/g; s/-Jun-/-06-/g; s/-Jul-/-07-/g; s/-Aug-/-08-/g
        s/-Sep-/-09-/g; s/-Oct-/-10-/g; s/-Nov-/-11-/g; s/-Dec-/-12-/g

        # Categorizar por c√≥digo de estado
        s/\|20[0-9]\|/|INFO|/g
        s/\|30[0-9]\|/|WARN|/g
        s/\|40[0-9]\|/|ERROR|/g
        s/\|50[0-9]\|/|ERROR|/g
    ' "$input" > "$output"
}

normalize_nginx_combined() {
    local input="$1"
    local output="$2"

    log_message "INFO" "Normalizando formato Nginx Combined..."

    awk '{
        # Extraer IP
        ip = $1

        # Extraer timestamp (entre corchetes)
        match($0, /\[([^\]]+)\]/, timestamp_match)
        timestamp = timestamp_match[1]

        # Extraer m√©todo y URL (entre comillas)
        match($0, /"([A-Z]+) ([^ ]+) ([^"]+)"/, request_match)
        method = request_match[1]
        url = request_match[2]

        # Extraer c√≥digo de estado y tama√±o
        match($0, /" ([0-9]{3}) ([0-9]+) /, response_match)
        status_code = response_match[1]
        size = response_match[2]

        # Determinar nivel de log basado en c√≥digo de estado
        if (status_code ~ /^20[0-9]$/) level = "INFO"
        else if (status_code ~ /^30[0-9]$/) level = "WARN"
        else if (status_code ~ /^[45][0-9][0-9]$/) level = "ERROR"
        else level = "INFO"

        # Formato de salida est√°ndar: timestamp|ip|level|source|message|status|size|extra
        printf "%s|%s|%s|Nginx|%s %s|%s|%s|\n",
               timestamp, ip, level, method, url, status_code, size
    }' "$input" > "$output"
}

normalize_application_log() {
    local input="$1"
    local output="$2"

    log_message "INFO" "Normalizando formato Application Log..."

    sed -E '
        # Formato: 2024-03-15 09:15:30 [INFO] User login successful: user123
        s/^([0-9]{4}-[0-9]{2}-[0-9]{2} [0-9:]+) \[([A-Z]+)\] (.*)$/\1|unknown|\2|Application|\3|||/

        # Extraer IPs si est√°n presentes
        s/([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})/\1/g

        # Detectar fuente espec√≠fica basada en mensaje
        s/\|Application\|(.*(database|db|sql).*)$/|Application-DB|\1/i
        s/\|Application\|(.*(auth|login|password).*)$/|Application-Auth|\1/i
        s/\|Application\|(.*(api|rest|endpoint).*)$/|Application-API|\1/i
    ' "$input" > "$output"
}

normalize_syslog() {
    local input="$1"
    local output="$2"

    log_message "INFO" "Normalizando formato Syslog..."

    awk '{
        # Formato syslog: Mar 15 09:15:30 hostname service[pid]: message
        month = $1
        day = $2
        time = $3
        hostname = $4

        # Convertir mes a n√∫mero
        months["Jan"]=1; months["Feb"]=2; months["Mar"]=3; months["Apr"]=4
        months["May"]=5; months["Jun"]=6; months["Jul"]=7; months["Aug"]=8
        months["Sep"]=9; months["Oct"]=10; months["Nov"]=11; months["Dec"]=12

        # Construir timestamp (asumir a√±o actual)
        timestamp = strftime("%Y") "-" sprintf("%02d", months[month]) "-" sprintf("%02d", day) " " time

        # Extraer servicio y mensaje
        rest = ""
        for (i=5; i<=NF; i++) rest = rest $i " "

        # Determinar nivel basado en palabras clave
        level = "INFO"
        if (match(rest, /(error|fail|critical|fatal)/i)) level = "ERROR"
        else if (match(rest, /(warn|warning)/i)) level = "WARN"

        # Formato de salida est√°ndar: timestamp|ip|level|source|message|status|size|extra
        printf "%s|%s|%s|Syslog|%s|||\n", timestamp, hostname, level, rest
    }' "$input" > "$output"
}

# =============================================================================
# FUNCI√ìN PRINCIPAL DE NORMALIZACI√ìN
# =============================================================================

normalize_log_file() {
    local input_file="$1"
    local output_file="$2"
    local format="$3"

    # Crear directorio de salida si no existe
    mkdir -p "$(dirname "$output_file")"

    case "$format" in
        "apache_combined"|"apache_common")
            normalize_apache_combined "$input_file" "$output_file"
            ;;
        "nginx_combined")
            normalize_nginx_combined "$input_file" "$output_file"
            ;;
        "application")
            normalize_application_log "$input_file" "$output_file"
            ;;
        "syslog")
            normalize_syslog "$input_file" "$output_file"
            ;;
        "json")
            log_message "WARN" "Normalizaci√≥n JSON no implementada a√∫n"
            cp "$input_file" "$output_file"
            ;;
        *)
            log_message "WARN" "Formato desconocido, copiando archivo sin cambios"
            cp "$input_file" "$output_file"
            ;;
    esac

    local lines_processed=$(wc -l < "$output_file")
    log_message "SUCCESS" "Normalizaci√≥n completa: $lines_processed l√≠neas procesadas"
}
```

**[PANTALLA: Ejecutando ejemplo de normalizaci√≥n]**

¬°Incre√≠ble! Has creado el primer m√≥dulo de tu analizador profesional. Este normalizador puede manejar los formatos de log m√°s comunes en la industria y convertirlos a un formato est√°ndar para an√°lisis posterior.

---

**[PANTALLA: Creando el m√≥dulo de an√°lisis de patrones]**

Ahora vamos a construir el cerebro anal√≠tico del sistema: el **analizador de patrones**. Este m√≥dulo extrae m√©tricas clave, identifica tendencias y prepara los datos para la detecci√≥n de anomal√≠as y la generaci√≥n de reportes.

```bash
nano modules/pattern_analyzer.sh
```

```bash
#!/bin/bash
# modules/pattern_analyzer.sh - An√°lisis de patrones y m√©tricas

analyze_patterns() {
    local input_file="$1"
    local output_file="$2"

    # Extraer m√©tricas clave: errores, advertencias, tiempos de respuesta, IPs
    awk -F'|' '
    BEGIN {
        print "{" > output
        print "  \"total_lines\": 0," > output
        print "  \"errors\": 0," > output
        print "  \"warnings\": 0," > output
        print "  \"info\": 0," > output
        print "  \"unique_ips\": []," > output
        print "  \"response_times\": []" > output
    }
    {
        total++
        level = $3
        ip = $2
        if (level == "ERROR") errors++
        else if (level == "WARN") warnings++
        else if (level == "INFO") info++
        ips[ip]++
        # Extraer tiempos de respuesta si existen
        if ($8 ~ /^[0-9.]+$/) {
            response_times[n++] = $8
        }
    }
    END {
        print "  \"total_lines\": " total ","
        print "  \"errors\": " errors ","
        print "  \"warnings\": " warnings ","
        print "  \"info\": " info ","
        printf "  \"unique_ips\": ["
        sep = ""
        for (ip in ips) {
            printf "%s\"%s\"", sep, ip
            sep = ", "
        }
        print "],"
        printf "  \"response_times\": ["
        for (i = 0; i < n; i++) {
            printf "%s%s", (i==0?"":", "), response_times[i]
        }
        print "]"
        print "}"
    }' "$input_file" > "$output_file"
}
```

**[PANTALLA: Ejecutando el analizador de patrones y mostrando el JSON resultante]**

```bash
chmod +x pattern_analyzer.sh
./pattern_analyzer.sh
```

#### [95:00 - 100:00] DETECTOR DE ANOMAL√çAS Y ALERTAS

**[PANTALLA: Creando el m√≥dulo de detecci√≥n de anomal√≠as]**

El siguiente paso es el **detector de anomal√≠as**. Este m√≥dulo identifica comportamientos inusuales, genera alertas autom√°ticas y ayuda a prevenir incidentes antes de que ocurran.

```bash
nano modules/anomaly_detector.sh
```

```bash
#!/bin/bash
# modules/anomaly_detector.sh - Detecci√≥n de anomal√≠as y alertas

detect_anomalies() {
    local input_file="$1"
    local output_file="$2"

    # Analizar el archivo normalizado para detectar patrones an√≥malos
    awk -F'|' '
    {
        level = $3
        ip = $2
        if (level == "ERROR") error_count[ip]++
        if (level == "WARN") warn_count[ip]++
        if ($8 ~ /^[0-9.]+$/ && $8 > 2.0) slow_responses[ip]++
        if ($5 ~ /login|auth/i && level == "ERROR") failed_logins[ip]++
    }
    END {
        print "{" > output
        print "  \"alerts\": [" > output
        sep = ""
        for (ip in error_count) {
            if (error_count[ip] > 10) {
                printf "%s{\"type\": \"error_burst\", \"ip\": \"%s\", \"count\": %d}", sep, ip, error_count[ip]
                sep = ", "
            }
        }
        for (ip in slow_responses) {
            if (slow_responses[ip] > 5) {
                printf "%s{\"type\": \"slow_response\", \"ip\": \"%s\", \"count\": %d}", sep, ip, slow_responses[ip]
                sep = ", "
            }
        }
        for (ip in failed_logins) {
            if (failed_logins[ip] > 5) {
                printf "%s{\"type\": \"failed_logins\", \"ip\": \"%s\", \"count\": %d}", sep, ip, failed_logins[ip]
                sep = ", "
            }
        }
        print "]"
        print "}"
    }' "$input_file" > "$output_file"
}
```

**[PANTALLA: Mostrando ejemplos de alertas generadas]**

```bash
chmod +x anomaly_detector.sh
./anomaly_detector.sh
```

#### [100:00 - 110:00] GENERADOR DE REPORTES PROFESIONAL

**[PANTALLA: Creando el m√≥dulo de generaci√≥n de reportes]**

El √∫ltimo gran componente es el **generador de reportes**. Este m√≥dulo toma los resultados del an√°lisis y las alertas, y produce un dashboard HTML profesional listo para ejecutivos y equipos t√©cnicos.

```bash
nano modules/report_generator.sh
```

```bash
#!/bin/bash
# modules/report_generator.sh - Generador de reportes HTML

generate_report() {
    local analysis_file="$1"
    local alerts_file="$2"
    local output_file="$3"

    # Generar un HTML simple con los resultados
    cat <<EOF > "$output_file"
<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Reporte de An√°lisis de Logs</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2em; }
    h1 { color: #2c3e50; }
    .alert { color: #c0392b; font-weight: bold; }
    .metric { color: #2980b9; }
    .section { margin-bottom: 2em; }
    pre { background: #f4f4f4; padding: 1em; border-radius: 5px; }
  </style>
</head>
<body>
  <h1>Reporte de An√°lisis de Logs</h1>
  <div class="section">
    <h2>M√©tricas Generales</h2>
    <pre>$(cat "$analysis_file")</pre>
  </div>
  <div class="section">
    <h2>Alertas Detectadas</h2>
    <pre>$(cat "$alerts_file")</pre>
  </div>
  <div class="section">
    <h2>Resumen Ejecutivo</h2>
    <ul>
      <li>Errores cr√≠ticos, picos de actividad y anomal√≠as resaltadas autom√°ticamente.</li>
      <li>Recomendaciones para mitigaci√≥n y pr√≥ximos pasos.</li>
    </ul>
  </div>
  <footer>
    <hr>
    <p>Generado autom√°ticamente por el Analizador de Logs - Bootcamp Bash Scripting</p>
  </footer>
</body>
</html>
EOF
}
```

**[PANTALLA: Mostrando el dashboard HTML generado]**

```bash
chmod +x report_generator.sh
./report_generator.sh
```

#### [110:00 - 115:00] SISTEMA DE DEMOSTRACI√ìN Y TESTING

**[PANTALLA: Creando datos de ejemplo y ejecutando la demo completa]**

Para que puedas probar todo el sistema de principio a fin, incluimos un modo de demostraci√≥n que genera datos de ejemplo y ejecuta el flujo completo:

```bash
# En log_analyzer.sh, funci√≥n run_demo:
run_demo() {
    log_message "INFO" "Generando datos de ejemplo..."
    cat << 'EOF' > "${DATA_DIR}/demo.log"
192.168.1.101|2024-03-15 09:15:30|INFO|Apache|GET /index.html|200|2326|0.045
10.0.0.50|2024-03-15 09:16:45|ERROR|Apache|POST /login|401|1024|0.012
192.168.1.102|2024-03-15 09:17:12|INFO|Apache|GET /api/users|200|5120|0.500
10.0.0.50|2024-03-15 09:18:01|ERROR|Apache|POST /login|401|1024|2.500
192.168.1.103|2024-03-15 09:19:33|INFO|Apache|GET /products|200|8192|0.200
EOF
    analyze_log_file "${DATA_DIR}/demo.log" "demo"
}
```

**[PANTALLA: Ejecutando la demo y mostrando el reporte final]**

```bash
./log_analyzer.sh --demo
```

#### [115:00 - 120:00] CONCLUSIONES Y SIGUIENTES PASOS

**[PANTALLA: Resumen visual de todo el proyecto]**

¬°Felicidades! Has construido un **analizador de logs profesional** desde cero, integrando:

- Normalizaci√≥n multi-formato
- An√°lisis estad√≠stico y extracci√≥n de m√©tricas
- Detecci√≥n autom√°tica de anomal√≠as y alertas
- Generaci√≥n de dashboards HTML ejecutivos
- Testing y demostraci√≥n automatizada

**[PANTALLA: Call to action final]**

- Usa este proyecto como base para tus propios sistemas de monitoreo
- Pres√©ntalo en entrevistas o a tu equipo
- Contin√∫a explorando Bash avanzado y automatizaci√≥n

---
