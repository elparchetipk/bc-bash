---

## üîß LECCI√ìN 8.1: ARQUITECTURA DE SISTEMAS DE AUTOMATIZACI√ìN

### Concepto: De Scripts Aislados a Sistemas Coherentes

La diferencia entre un conjunto de scripts y un **sistema de automatizaci√≥n** radica en el dise√±o arquitectural. Un sistema bien dise√±ado es modular, mantenible, escalable y resiliente.

### 8.1.1 Patrones de Arquitectura para Automatizaci√≥n

#### **Patr√≥n MVC para Scripts Complejos**

```bash
#!/bin/bash
# Framework MVC para automatizaci√≥n
# Estructura: Model-View-Controller adaptada a Bash

# === MODEL: Gesti√≥n de datos y estado ===
source "$(dirname "${BASH_SOURCE[0]}")/lib/model.sh"
source "$(dirname "${BASH_SOURCE[0]}")/lib/config.sh"

# === VIEW: Presentaci√≥n y logging ===
source "$(dirname "${BASH_SOURCE[0]}")/lib/view.sh"
source "$(dirname "${BASH_SOURCE[0]}")/lib/logger.sh"

# === CONTROLLER: L√≥gica de negocio ===
source "$(dirname "${BASH_SOURCE[0]}")/lib/controller.sh"
source "$(dirname "${BASH_SOURCE[0]}")/lib/workflow.sh"

# Punto de entrada principal
main() {
    # Inicializar componentes
    config_load "$@"
    logger_init
    view_init
    
    # Ejecutar workflow
    controller_execute_workflow
    
    # Cleanup
    cleanup_all
}

# Ejecutar solo si es llamado directamente
[[ "${BASH_SOURCE[0]}" == "${0}" ]] && main "$@"
```

#### **Sistema de Configuraci√≥n Centralizada**

```bash
#!/bin/bash
# lib/config.sh - Sistema de configuraci√≥n avanzado

declare -A CONFIG
declare -A CONFIG_METADATA

# Configuraci√≥n con validaci√≥n y tipos
config_define() {
    local key="$1"
    local default_value="$2"
    local type="${3:-string}"
    local description="$4"
    local required="${5:-false}"
    
    CONFIG["$key"]="$default_value"
    CONFIG_METADATA["${key}_type"]="$type"
    CONFIG_METADATA["${key}_desc"]="$description"
    CONFIG_METADATA["${key}_required"]="$required"
}

config_load_from_file() {
    local config_file="$1"
    
    [[ ! -f "$config_file" ]] && return 1
    
    # Cargar configuraci√≥n de forma segura
    while IFS='=' read -r key value; do
        # Ignorar comentarios y l√≠neas vac√≠as
        [[ "$key" =~ ^[[:space:]]*# ]] && continue
        [[ -z "$key" ]] && continue
        
        # Validar que la configuraci√≥n existe
        if [[ -n "${CONFIG_METADATA[${key}_type]}" ]]; then
            config_set "$key" "$value"
        else
            logger_warn "Configuraci√≥n desconocida: $key"
        fi
    done < "$config_file"
}

config_set() {
    local key="$1"
    local value="$2"
    local type="${CONFIG_METADATA[${key}_type]:-string}"
    
    # Validar tipo
    case "$type" in
        "int")
            [[ "$value" =~ ^[0-9]+$ ]] || {
                logger_error "Valor inv√°lido para $key: debe ser entero"
                return 1
            }
            ;;
        "bool")
            [[ "$value" =~ ^(true|false|yes|no|1|0)$ ]] || {
                logger_error "Valor inv√°lido para $key: debe ser booleano"
                return 1
            }
            ;;
        "file")
            [[ -f "$value" ]] || {
                logger_error "Archivo no encontrado para $key: $value"
                return 1
            }
            ;;
        "dir")
            [[ -d "$value" ]] || {
                logger_error "Directorio no encontrado para $key: $value"
                return 1
            }
            ;;
    esac
    
    CONFIG["$key"]="$value"
    logger_debug "Configuraci√≥n actualizada: $key=$value"
}

config_get() {
    local key="$1"
    local default="$2"
    
    echo "${CONFIG[$key]:-$default}"
}

# Ejemplo de configuraci√≥n
config_init() {
    # Configuraciones del sistema
    config_define "app.name" "AutomationSystem" "string" "Nombre de la aplicaci√≥n"
    config_define "app.version" "1.0.0" "string" "Versi√≥n de la aplicaci√≥n"
    config_define "app.debug" "false" "bool" "Modo debug activado"
    
    # Configuraciones de logging
    config_define "log.level" "INFO" "string" "Nivel de logging"
    config_define "log.file" "/tmp/automation.log" "string" "Archivo de log"
    config_define "log.max_size" "100" "int" "Tama√±o m√°ximo del log en MB"
    
    # Configuraciones de ejecuci√≥n
    config_define "exec.timeout" "3600" "int" "Timeout en segundos"
    config_define "exec.max_parallel" "5" "int" "Procesos paralelos m√°ximos"
    config_define "exec.retry_count" "3" "int" "Intentos de reintento"
    
    # Cargar configuraciones de archivos
    local config_files=(
        "/etc/automation/config"
        "$HOME/.automation/config"
        "./config/automation.conf"
    )
    
    for config_file in "${config_files[@]}"; do
        [[ -f "$config_file" ]] && config_load_from_file "$config_file"
    done
}
```

### 8.1.2 Sistema de M√≥dulos y Dependencias

#### **Gestor de M√≥dulos Din√°mico**

```bash
#!/bin/bash
# lib/module_manager.sh - Sistema de gesti√≥n de m√≥dulos

declare -A LOADED_MODULES
declare -A MODULE_DEPENDENCIES
declare -A MODULE_VERSIONS

module_define() {
    local module_name="$1"
    local module_path="$2"
    local version="${3:-1.0.0}"
    local dependencies="$4"  # "mod1,mod2,mod3"
    
    MODULE_DEPENDENCIES["$module_name"]="$dependencies"
    MODULE_VERSIONS["$module_name"]="$version"
    
    logger_debug "M√≥dulo definido: $module_name v$version"
}

module_load() {
    local module_name="$1"
    local force_reload="${2:-false}"
    
    # Verificar si ya est√° cargado
    if [[ "${LOADED_MODULES[$module_name]}" == "true" && "$force_reload" != "true" ]]; then
        return 0
    fi
    
    logger_info "Cargando m√≥dulo: $module_name"
    
    # Cargar dependencias primero
    local dependencies="${MODULE_DEPENDENCIES[$module_name]}"
    if [[ -n "$dependencies" ]]; then
        IFS=',' read -ra deps <<< "$dependencies"
        for dep in "${deps[@]}"; do
            module_load "$dep" || {
                logger_error "Error cargando dependencia: $dep"
                return 1
            }
        done
    fi
    
    # Cargar el m√≥dulo
    local module_path="modules/${module_name}.sh"
    if [[ -f "$module_path" ]]; then
        source "$module_path" || {
            logger_error "Error cargando m√≥dulo: $module_name"
            return 1
        }
        
        # Ejecutar funci√≥n de inicializaci√≥n si existe
        if declare -f "${module_name}_init" &>/dev/null; then
            "${module_name}_init" || {
                logger_error "Error inicializando m√≥dulo: $module_name"
                return 1
            }
        fi
        
        LOADED_MODULES["$module_name"]="true"
        logger_info "M√≥dulo cargado exitosamente: $module_name"
        return 0
    else
        logger_error "M√≥dulo no encontrado: $module_path"
        return 1
    fi
}

module_unload() {
    local module_name="$1"
    
    # Ejecutar funci√≥n de cleanup si existe
    if declare -f "${module_name}_cleanup" &>/dev/null; then
        "${module_name}_cleanup"
    fi
    
    unset LOADED_MODULES["$module_name"]
    logger_info "M√≥dulo descargado: $module_name"
}

module_list() {
    echo "=== M√ìDULOS CARGADOS ==="
    for module in "${!LOADED_MODULES[@]}"; do
        local version="${MODULE_VERSIONS[$module]}"
        echo "  $module v$version"
    done
}

# Definir m√≥dulos del sistema
module_system_init() {
    module_define "logger" "lib/logger.sh" "2.0.0" ""
    module_define "config" "lib/config.sh" "1.5.0" "logger"
    module_define "database" "lib/database.sh" "1.0.0" "logger,config"
    module_define "api_client" "lib/api_client.sh" "1.2.0" "logger,config"
    module_define "workflow" "lib/workflow.sh" "1.0.0" "logger,config,database"
}
```

### 8.1.3 Sistema de Versionado y Distribuci√≥n

#### **Gestor de Versiones Autom√°tico**

```bash
#!/bin/bash
# tools/version_manager.sh - Sistema de versionado sem√°ntico

VERSION_FILE="VERSION"
CHANGELOG_FILE="CHANGELOG.md"

version_get_current() {
    [[ -f "$VERSION_FILE" ]] && cat "$VERSION_FILE" || echo "0.0.0"
}

version_parse() {
    local version="$1"
    local parts
    
    IFS='.' read -ra parts <<< "$version"
    echo "${parts[0]:-0}" "${parts[1]:-0}" "${parts[2]:-0}"
}

version_increment() {
    local type="$1"  # major, minor, patch
    local current_version
    current_version=$(version_get_current)
    
    read -r major minor patch <<< "$(version_parse "$current_version")"
    
    case "$type" in
        "major")
            ((major++))
            minor=0
            patch=0
            ;;
        "minor")
            ((minor++))
            patch=0
            ;;
        "patch")
            ((patch++))
            ;;
        *)
            logger_error "Tipo de versi√≥n inv√°lido: $type"
            return 1
            ;;
    esac
    
    local new_version="$major.$minor.$patch"
    echo "$new_version" > "$VERSION_FILE"
    
    logger_info "Versi√≥n actualizada: $current_version ‚Üí $new_version"
    echo "$new_version"
}

version_tag_release() {
    local version="$1"
    local message="${2:-Release version $version}"
    
    # Crear tag de git
    git tag -a "v$version" -m "$message"
    
    # Generar release notes
    version_generate_release_notes "$version"
    
    logger_info "Release tagged: v$version"
}

version_generate_release_notes() {
    local version="$1"
    local since_tag
    since_tag=$(git describe --tags --abbrev=0 HEAD^ 2>/dev/null || echo "")
    
    local output_file="releases/v${version}.md"
    mkdir -p "releases"
    
    {
        echo "# Release v$version"
        echo ""
        echo "Release Date: $(date '+%Y-%m-%d')"
        echo ""
        echo "## Changes"
        echo ""
        
        if [[ -n "$since_tag" ]]; then
            git log --pretty=format:"- %s" "$since_tag..HEAD"
        else
            git log --pretty=format:"- %s"
        fi
        
        echo ""
        echo ""
        echo "## Files Changed"
        echo ""
        
        if [[ -n "$since_tag" ]]; then
            git diff --name-only "$since_tag..HEAD" | sed 's/^/- /'
        fi
        
    } > "$output_file"
    
    logger_info "Release notes generadas: $output_file"
}
```

---

## üîß LECCI√ìN 8.2: ORQUESTACI√ìN DE PROCESOS Y WORKFLOWS

### Concepto: Coordinaci√≥n Inteligente de Procesos

La orquestaci√≥n va m√°s all√° de ejecutar scripts en secuencia. Implica gesti√≥n de estado, manejo de errores sofisticado, recuperaci√≥n autom√°tica y coordinaci√≥n de procesos distribuidos.

### 8.2.1 Engine de Workflows Avanzado

#### **Workflow Engine con Estados**

```bash
#!/bin/bash
# lib/workflow_engine.sh - Motor de workflows con estados

declare -A WORKFLOW_STEPS
declare -A WORKFLOW_STATE
declare -A WORKFLOW_METADATA

# Estados posibles: pending, running, completed, failed, skipped
workflow_define_step() {
    local workflow_id="$1"
    local step_id="$2"
    local command="$3"
    local dependencies="$4"
    local timeout="${5:-300}"
    local retry_count="${6:-1}"

    local step_key="${workflow_id}.${step_id}"

    WORKFLOW_STEPS["$step_key"]="$command"
    WORKFLOW_STATE["${step_key}.status"]="pending"
    WORKFLOW_STATE["${step_key}.dependencies"]="$dependencies"
    WORKFLOW_STATE["${step_key}.timeout"]="$timeout"
    WORKFLOW_STATE["${step_key}.retry_count"]="$retry_count"
    WORKFLOW_STATE["${step_key}.current_retry"]="0"

    logger_debug "Workflow step definido: $step_key"
}

workflow_can_execute() {
    local workflow_id="$1"
    local step_id="$2"
    local step_key="${workflow_id}.${step_id}"

    # Verificar que el step est√© pendiente
    local status="${WORKFLOW_STATE[${step_key}.status]}"
    [[ "$status" != "pending" ]] && return 1

    # Verificar dependencias
    local dependencies="${WORKFLOW_STATE[${step_key}.dependencies]}"
    if [[ -n "$dependencies" ]]; then
        IFS=',' read -ra deps <<< "$dependencies"
        for dep in "${deps[@]}"; do
            local dep_status="${WORKFLOW_STATE[${workflow_id}.${dep}.status]}"
            if [[ "$dep_status" != "completed" ]]; then
                return 1
            fi
        done
    fi

    return 0
}

workflow_execute_step() {
    local workflow_id="$1"
    local step_id="$2"
    local step_key="${workflow_id}.${step_id}"

    local command="${WORKFLOW_STEPS[$step_key]}"
    local timeout="${WORKFLOW_STATE[${step_key}.timeout]}"
    local max_retries="${WORKFLOW_STATE[${step_key}.retry_count]}"
    local current_retry="${WORKFLOW_STATE[${step_key}.current_retry]}"

    logger_info "Ejecutando step: $step_key (intento $((current_retry + 1))/$max_retries)"

    # Marcar como running
    WORKFLOW_STATE["${step_key}.status"]="running"
    WORKFLOW_STATE["${step_key}.start_time"]=$(date +%s)

    # Ejecutar con timeout
    local output_file="/tmp/workflow_${workflow_id}_${step_id}_output"
    local exit_code

    if timeout "$timeout" bash -c "$command" &> "$output_file"; then
        # √âxito
        WORKFLOW_STATE["${step_key}.status"]="completed"
        WORKFLOW_STATE["${step_key}.end_time"]=$(date +%s)
        WORKFLOW_STATE["${step_key}.output"]="$output_file"

        logger_info "Step completado: $step_key"
        return 0
    else
        exit_code=$?

        # Incrementar contador de reintentos
        ((current_retry++))
        WORKFLOW_STATE["${step_key}.current_retry"]="$current_retry"

        if [[ "$current_retry" -lt "$max_retries" ]]; then
            # Reintentar
            WORKFLOW_STATE["${step_key}.status"]="pending"
            logger_warn "Step fall√≥, reintentando: $step_key ($current_retry/$max_retries)"
            sleep $((current_retry * 2))  # Backoff exponencial
            workflow_execute_step "$workflow_id" "$step_id"
        else
            # Fallo definitivo
            WORKFLOW_STATE["${step_key}.status"]="failed"
            WORKFLOW_STATE["${step_key}.error_code"]="$exit_code"
            WORKFLOW_STATE["${step_key}.error_output"]="$output_file"

            logger_error "Step fall√≥ definitivamente: $step_key (c√≥digo: $exit_code)"
            return 1
        fi
    fi
}

workflow_execute() {
    local workflow_id="$1"
    local max_parallel="${2:-3}"

    logger_info "Iniciando workflow: $workflow_id (max_parallel: $max_parallel)"

    local running_jobs=0
    local completed_steps=0
    local failed_steps=0
    local total_steps

    # Contar total de steps
    total_steps=$(printf '%s\n' "${!WORKFLOW_STEPS[@]}" | grep "^${workflow_id}\." | wc -l)

    while [[ $((completed_steps + failed_steps)) -lt $total_steps ]]; do
        # Buscar steps que pueden ejecutarse
        for step_key in "${!WORKFLOW_STEPS[@]}"; do
            [[ "$step_key" =~ ^${workflow_id}\.(.+)$ ]] || continue
            local step_id="${BASH_REMATCH[1]}"

            # Verificar si puede ejecutarse y no hay demasiados jobs
            if workflow_can_execute "$workflow_id" "$step_id" && [[ $running_jobs -lt $max_parallel ]]; then
                # Ejecutar en background
                (
                    workflow_execute_step "$workflow_id" "$step_id"
                    echo "$step_key:$?" > "/tmp/workflow_${workflow_id}_${step_id}_result"
                ) &

                ((running_jobs++))
                logger_debug "Job iniciado para step: $step_key (running: $running_jobs)"
            fi
        done

        # Verificar jobs completados
        for step_key in "${!WORKFLOW_STEPS[@]}"; do
            [[ "$step_key" =~ ^${workflow_id}\.(.+)$ ]] || continue
            local step_id="${BASH_REMATCH[1]}"
            local result_file="/tmp/workflow_${workflow_id}_${step_id}_result"

            if [[ -f "$result_file" ]]; then
                local result
                result=$(cat "$result_file")
                rm "$result_file"

                local exit_code="${result#*:}"

                ((running_jobs--))

                if [[ "$exit_code" == "0" ]]; then
                    ((completed_steps++))
                else
                    ((failed_steps++))
                fi

                logger_debug "Job terminado: $step_key (exit: $exit_code, running: $running_jobs)"
            fi
        done

        # Evitar busy wait
        sleep 1
    done

    # Esperar jobs restantes
    wait

    if [[ $failed_steps -gt 0 ]]; then
        logger_error "Workflow completado con errores: $workflow_id ($failed_steps fallos)"
        return 1
    else
        logger_info "Workflow completado exitosamente: $workflow_id ($completed_steps steps)"
        return 0
    fi
}

workflow_status() {
    local workflow_id="$1"

    echo "=== ESTADO DEL WORKFLOW: $workflow_id ==="
    printf "%-20s %-10s %-10s %-10s\n" "STEP" "ESTADO" "REINTENTOS" "TIEMPO"
    echo "--------------------------------------------------------"

    for step_key in "${!WORKFLOW_STEPS[@]}"; do
        [[ "$step_key" =~ ^${workflow_id}\.(.+)$ ]] || continue
        local step_id="${BASH_REMATCH[1]}"

        local status="${WORKFLOW_STATE[${step_key}.status]}"
        local retries="${WORKFLOW_STATE[${step_key}.current_retry]}"
        local start_time="${WORKFLOW_STATE[${step_key}.start_time]}"
        local end_time="${WORKFLOW_STATE[${step_key}.end_time]}"

        local duration=""
        if [[ -n "$start_time" && -n "$end_time" ]]; then
            duration="$((end_time - start_time))s"
        elif [[ -n "$start_time" ]]; then
            duration="$(($(date +%s) - start_time))s"
        fi

        printf "%-20s %-10s %-10s %-10s\n" "$step_id" "$status" "$retries" "$duration"
    done
}
```

### 8.2.2 Sistema de Colas y Procesamiento As√≠ncrono

#### **Queue Manager con Prioridades**

```bash
#!/bin/bash
# lib/queue_manager.sh - Sistema de colas con prioridades

QUEUE_DIR="${QUEUE_DIR:-/tmp/automation_queues}"
QUEUE_WORKERS="${QUEUE_WORKERS:-3}"

queue_init() {
    mkdir -p "$QUEUE_DIR"/{high,normal,low,processing,completed,failed}

    # Crear archivo de control de workers
    echo "0" > "$QUEUE_DIR/active_workers"
}

queue_add_job() {
    local job_id="$1"
    local command="$2"
    local priority="${3:-normal}"  # high, normal, low
    local metadata="$4"

    local job_file="$QUEUE_DIR/$priority/${job_id}.job"

    {
        echo "ID=$job_id"
        echo "PRIORITY=$priority"
        echo "CREATED=$(date +%s)"
        echo "COMMAND=$command"
        echo "METADATA=$metadata"
        echo "STATUS=queued"
    } > "$job_file"

    logger_info "Job a√±adido a cola: $job_id (prioridad: $priority)"
}

queue_get_next_job() {
    local priorities=("high" "normal" "low")

    for priority in "${priorities[@]}"; do
        local job_file
        job_file=$(find "$QUEUE_DIR/$priority" -name "*.job" -type f | head -n1)

        if [[ -n "$job_file" ]]; then
            local job_id
            job_id=$(basename "$job_file" .job)

            # Mover a processing
            mv "$job_file" "$QUEUE_DIR/processing/"

            echo "$job_id"
            return 0
        fi
    done

    return 1
}

queue_process_job() {
    local job_id="$1"
    local job_file="$QUEUE_DIR/processing/${job_id}.job"

    [[ ! -f "$job_file" ]] && {
        logger_error "Job no encontrado: $job_id"
        return 1
    }

    # Cargar informaci√≥n del job
    source "$job_file"

    logger_info "Procesando job: $job_id"

    # Actualizar estado
    sed -i 's/STATUS=.*/STATUS=running/' "$job_file"
    echo "STARTED=$(date +%s)" >> "$job_file"

    # Ejecutar comando
    local output_file="$QUEUE_DIR/processing/${job_id}.output"
    local exit_code

    if eval "$COMMAND" &> "$output_file"; then
        # √âxito
        echo "COMPLETED=$(date +%s)" >> "$job_file"
        echo "EXIT_CODE=0" >> "$job_file"
        sed -i 's/STATUS=.*/STATUS=completed/' "$job_file"

        # Mover a completed
        mv "$job_file" "$QUEUE_DIR/completed/"
        mv "$output_file" "$QUEUE_DIR/completed/${job_id}.output"

        logger_info "Job completado: $job_id"
        return 0
    else
        exit_code=$?

        # Fallo
        echo "COMPLETED=$(date +%s)" >> "$job_file"
        echo "EXIT_CODE=$exit_code" >> "$job_file"
        sed -i 's/STATUS=.*/STATUS=failed/' "$job_file"

        # Mover a failed
        mv "$job_file" "$QUEUE_DIR/failed/"
        mv "$output_file" "$QUEUE_DIR/failed/${job_id}.output"

        logger_error "Job fall√≥: $job_id (c√≥digo: $exit_code)"
        return 1
    fi
}

queue_status() {
    echo "=== ESTADO DE COLAS ==="

    local priorities=("high" "normal" "low")
    for priority in "${priorities[@]}"; do
        local count
        count=$(find "$QUEUE_DIR/$priority" -name "*.job" | wc -l)
        echo "Cola $priority: $count jobs"
    done

    local processing
    processing=$(find "$QUEUE_DIR/processing" -name "*.job" | wc -l)
    echo "Procesando: $processing jobs"

    local completed
    completed=$(find "$QUEUE_DIR/completed" -name "*.job" | wc -l)
    echo "Completados: $completed jobs"

    local failed
    failed=$(find "$QUEUE_DIR/failed" -name "*.job" | wc -l)
    echo "Fallidos: $failed jobs"

    local active_workers
    active_workers=$(cat "$QUEUE_DIR/active_workers" 2>/dev/null || echo "0")
    echo "Workers activos: $active_workers"
}
```

---

## üîß LECCI√ìN 8.3: INTEGRACI√ìN CON ECOSISTEMAS EXTERNOS

### 8.3.1 Cliente de APIs Avanzado

#### **HTTP Client con Autenticaci√≥n y Retry**

```bash
#!/bin/bash
# lib/api_client.sh - Cliente HTTP avanzado

API_BASE_URL=""
API_TOKEN=""
API_TIMEOUT="${API_TIMEOUT:-30}"
API_MAX_RETRIES="${API_MAX_RETRIES:-3}"

api_init() {
    local base_url="$1"
    local token="$2"

    API_BASE_URL="$base_url"
    API_TOKEN="$token"

    logger_debug "API client inicializado: $base_url"
}

api_request() {
    local method="$1"
    local endpoint="$2"
    local data="$3"
    local content_type="${4:-application/json}"
    local retry_count=0

    local url="${API_BASE_URL}${endpoint}"
    local response_file="/tmp/api_response_$$"
    local headers_file="/tmp/api_headers_$$"

    # Preparar headers
    local curl_args=(
        --silent
        --show-error
        --location
        --max-time "$API_TIMEOUT"
        --write-out "%{http_code}"
        --dump-header "$headers_file"
        --output "$response_file"
    )

    # Autenticaci√≥n
    if [[ -n "$API_TOKEN" ]]; then
        curl_args+=(--header "Authorization: Bearer $API_TOKEN")
    fi

    # Content-Type
    if [[ -n "$data" ]]; then
        curl_args+=(
            --header "Content-Type: $content_type"
            --data "$data"
        )
    fi

    # M√©todo HTTP
    curl_args+=(--request "$method")

    while [[ $retry_count -le $API_MAX_RETRIES ]]; do
        logger_debug "API request: $method $url (intento $((retry_count + 1)))"

        local http_code
        http_code=$(curl "${curl_args[@]}" "$url" 2>/dev/null)
        local curl_exit_code=$?

        if [[ $curl_exit_code -eq 0 ]]; then
            # Verificar c√≥digo HTTP
            case "$http_code" in
                2[0-9][0-9])
                    # √âxito
                    logger_debug "API response: $http_code"

                    # Retornar respuesta
                    cat "$response_file"

                    # Cleanup
                    rm -f "$response_file" "$headers_file"
                    return 0
                    ;;
                4[0-9][0-9])
                    # Error del cliente (no reintentar)
                    logger_error "API error $http_code: $(cat "$response_file")"
                    rm -f "$response_file" "$headers_file"
                    return 1
                    ;;
                5[0-9][0-9])
                    # Error del servidor (reintentar)
                    logger_warn "API server error $http_code, reintentando..."
                    ;;
                *)
                    logger_warn "API response desconocida: $http_code"
                    ;;
            esac
        else
            logger_warn "Error de conexi√≥n (c√≥digo curl: $curl_exit_code)"
        fi

        ((retry_count++))

        if [[ $retry_count -le $API_MAX_RETRIES ]]; then
            local wait_time=$((retry_count * 2))
            logger_debug "Esperando ${wait_time}s antes del siguiente intento"
            sleep $wait_time
        fi
    done

    # Fall√≥ despu√©s de todos los reintentos
    logger_error "API request fall√≥ despu√©s de $API_MAX_RETRIES reintentos"
    rm -f "$response_file" "$headers_file"
    return 1
}

# M√©todos HTTP convenientes
api_get() {
    api_request "GET" "$1"
}

api_post() {
    api_request "POST" "$1" "$2" "${3:-application/json}"
}

api_put() {
    api_request "PUT" "$1" "$2" "${3:-application/json}"
}

api_delete() {
    api_request "DELETE" "$1"
}

api_patch() {
    api_request "PATCH" "$1" "$2" "${3:-application/json}"
}

# Helper para JSON
api_post_json() {
    local endpoint="$1"
    local json_data="$2"

    api_post "$endpoint" "$json_data" "application/json"
}

# Helper para form data
api_post_form() {
    local endpoint="$1"
    local form_data="$2"

    api_post "$endpoint" "$form_data" "application/x-www-form-urlencoded"
}

# Ejemplo de uso con autenticaci√≥n OAuth2
api_oauth2_login() {
    local client_id="$1"
    local client_secret="$2"
    local auth_url="$3"

    local auth_data="grant_type=client_credentials&client_id=$client_id&client_secret=$client_secret"

    local response
    response=$(api_post_form "/oauth/token" "$auth_data")

    if [[ $? -eq 0 ]]; then
        local token
        token=$(echo "$response" | jq -r '.access_token')

        if [[ "$token" != "null" && -n "$token" ]]; then
            API_TOKEN="$token"
            logger_info "Autenticaci√≥n OAuth2 exitosa"
            return 0
        fi
    fi

    logger_error "Error en autenticaci√≥n OAuth2"
    return 1
}
```

---

## üéØ PROYECTO PR√ÅCTICO: SISTEMA DE AUTOMATIZACI√ìN EMPRESARIAL

### Desaf√≠o: "DevOps Automation Hub"

Desarrollar√°s un **sistema completo de automatizaci√≥n** que integre todas las t√©cnicas aprendidas en el m√≥dulo. Este proyecto simula un entorno empresarial real donde necesitas coordinar m√∫ltiples procesos, integrar sistemas externos y mantener alta disponibilidad.

#### **Requerimientos del Sistema:**

1. **Dashboard de Control**

   - Interfaz web simple para monitorear workflows
   - Estado en tiempo real de todos los procesos
   - M√©tricas de performance y alertas

2. **Pipeline de CI/CD**

   - Detecci√≥n autom√°tica de cambios en Git
   - Ejecuci√≥n de tests y validaciones
   - Deployment automatizado a m√∫ltiples entornos

3. **Sistema de Monitoreo**

   - Recolecci√≥n de m√©tricas de sistema
   - Alertas inteligentes por email/Slack
   - Reportes autom√°ticos de performance

4. **Backup y Recovery**
   - Backup autom√°tico de bases de datos
   - Sincronizaci√≥n con cloud storage
   - Procedimientos de recovery automatizados

### üìã Criterios de Evaluaci√≥n

#### **Excelencia T√©cnica (40%)**

- **Arquitectura Modular**: Sistema bien estructurado y mantenible
- **Gesti√≥n de Errores**: Manejo robusto de fallos y recovery
- **Performance**: Optimizaci√≥n para alta carga y eficiencia
- **Seguridad**: Implementaci√≥n de mejores pr√°cticas de seguridad

#### **Integraci√≥n y Automatizaci√≥n (35%)**

- **APIs**: Integraci√≥n fluida con servicios externos
- **Workflows**: Orquestaci√≥n compleja de procesos
- **Monitoring**: Sistema de observabilidad completo
- **Escalabilidad**: Capacidad de manejar carga creciente

#### **Documentaci√≥n y Mantenibilidad (25%)**

- **Documentaci√≥n T√©cnica**: Gu√≠as claras de instalaci√≥n y uso
- **C√≥digo Limpio**: Est√°ndares de codificaci√≥n y comentarios
- **Testing**: Suite de tests automatizados
- **Operabilidad**: Facilidad de deployment y mantenimiento

---

## üéì CONCLUSIONES DEL M√ìDULO

### Lo que Has Logrado

Al completar este m√≥dulo has alcanzado el nivel de **Arquitecto de Automatizaci√≥n**, capaz de:

- ‚úÖ Dise√±ar sistemas complejos de automatizaci√≥n
- ‚úÖ Integrar m√∫ltiples tecnolog√≠as y servicios
- ‚úÖ Implementar patrones empresariales en Bash
- ‚úÖ Crear herramientas reutilizables y escalables
- ‚úÖ Manejar workflows distribuidos y concurrentes

### Competencias Profesionales Desarrolladas

**T√©cnicas:**

- Arquitectura de software para automatizaci√≥n
- Integraci√≥n de sistemas heterog√©neos
- Orquestaci√≥n de procesos complejos
- Desarrollo de frameworks empresariales

**Metodol√≥gicas:**

- An√°lisis de requerimientos de automatizaci√≥n
- Dise√±o de soluciones escalables
- Gesti√≥n de proyectos t√©cnicos
- Documentaci√≥n de sistemas complejos

**Personales:**

- Pensamiento sist√©mico y arquitectural
- Resoluci√≥n de problemas complejos
- Comunicaci√≥n t√©cnica efectiva
- Liderazgo en equipos de automatizaci√≥n

---

## üß≠ NAVEGACI√ìN DEL BOOTCAMP

### ‚¨ÖÔ∏è M√≥dulo Anterior

**[M√ìDULO 7: Optimizaci√≥n y Debugging](../modulo7/README.md)**

- Debugging y troubleshooting profesional
- Optimizaci√≥n de performance avanzada
- Seguridad y auditor√≠a de scripts
- Herramientas de monitoring y profiling

### üìö Recursos Adicionales

#### **Documentaci√≥n T√©cnica**

- [Gu√≠as de Automatizaci√≥n](../_docs/automation/)
- [Patrones de Arquitectura](../_docs/patterns/)
- [Casos de Uso Empresariales](../_docs/enterprise/)

#### **Herramientas y Scripts**

- [Framework de Automatizaci√≥n](./tools/automation-framework/)
- [Templates de Proyectos](./templates/)
- [Ejemplos de Integraci√≥n](./examples/)

#### **Proyecto Final**

- [Especificaciones del Proyecto](./proyectos/devops-automation-hub/)
- [Criterios de Evaluaci√≥n](./proyectos/evaluation-criteria.md)
- [Entrega y Presentaci√≥n](./proyectos/submission-guide.md)

---

## üèÜ CERTIFICACI√ìN

### Requisitos para Certificaci√≥n

Para obtener la **certificaci√≥n oficial del Bootcamp Bash Scripting** debes completar:

1. ‚úÖ Todos los ejercicios de los 8 m√≥dulos
2. ‚úÖ Los 8 proyectos pr√°cticos modulares
3. ‚úÖ El proyecto final del M√≥dulo 8
4. ‚úÖ La evaluaci√≥n t√©cnica final

### Pr√≥ximos Pasos

**¬°Felicitaciones por completar el bootcamp!** üéâ

Como **Bash Scripting Expert** certificado, est√°s preparado para:

- Liderar proyectos de automatizaci√≥n empresarial
- Dise√±ar arquitecturas DevOps robustas
- Mentorear equipos en scripting avanzado
- Contribuir a proyectos open source de automatizaci√≥n

---

_¬°Has completado un viaje extraordinario desde scripts b√°sicos hasta arquitecturas empresariales complejas! Tu expertise en Bash scripting te abre puertas a roles avanzados en DevOps, SRE, y Arquitectura de Sistemas._

**¬°Ahora eres oficialmente un Bash Hero!** ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç‚ôÄÔ∏è
